import os
import json
import base64
import requests
from tqdm import tqdm
from termcolor import cprint
import google.auth
import google.auth.transport.requests
from google.oauth2 import service_account

# --- 1. é…ç½®åŒº (Configuration Section) ---
# è¯·åœ¨æ­¤å¤„ä¿®æ”¹æ‚¨çš„ä¸ªäººé…ç½®

# é¡¹ç›®å’Œæ¨¡å‹é…ç½®
VERTEX_AI_CONFIG = {
    "project_id": "gen-lang-client-0514315738",
    "location": "us-central1",
    # ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘è¯·åŠ¡å¿…ä¿®æ”¹ä¸ºæ‚¨çš„æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶çš„çœŸå®è·¯å¾„
    "credentials_path": "/home/yxcui/FM-Bridge/testing_file/gen-lang-client-0514315738-faeaf04b384e.json",
    "model_name": "gemini-2.5-flash" 
}

# ä»£ç†é…ç½®
PROXY_CONFIG = {
    # å¦‚æœæ‚¨ä¸éœ€è¦ä»£ç†ï¼Œè¯·å°†æ­¤è¡Œè®¾ç½®ä¸º None, ä¾‹å¦‚ï¼š'https': None
    'https': 'socks5://hkumedai:bestpaper@66.42.72.8:54321' 
}

# ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘è¯·ä¿®æ”¹ä¸ºæ‚¨çš„æ•°æ®é›†æ ¹ç›®å½•
BASE_DATA_PATH = "/home/yxcui/FM-Bridge/testing_file/test_dataset/cropped_20_slices_image"


# --- 2. è¾…åŠ©å‡½æ•° (Helper Functions) ---

def encode_image_to_base64(image_path):
    # (æ­¤å‡½æ•°ç”¨äºå°†å›¾ç‰‡ç¼–ç ä¸ºBase64)
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError:
        cprint(f"Warning: Image file not found at {image_path}. Skipping.", 'red')
        return None

# --- 3. æ™ºèƒ½ä½“æ ¸å¿ƒç±» (Agent Core Class) ---

class Agent:
    def __init__(self, instruction, role):
        # (æ­¤å¤„çš„ Agent ç±»ä¸æˆ‘ä»¬ä¹‹å‰ç‰ˆæœ¬ç›¸åŒï¼Œä½¿ç”¨ Gemini API)
        self.system_instruction = {"parts": [{"text": instruction}]}
        self.role = role
        self.config = VERTEX_AI_CONFIG
        self.proxies = PROXY_CONFIG if PROXY_CONFIG.get('https') else None

    def _get_access_token(self):
        # (æ­¤å‡½æ•°ç”¨äºé€šè¿‡æœåŠ¡è´¦å·è·å–è®¿é—®ä»¤ç‰Œ)
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.config['credentials_path'],
                scopes=['https://www.googleapis.com/auth/cloud-platform']
            )
            auth_req = google.auth.transport.requests.Request()
            credentials.refresh(auth_req)
            return credentials.token
        except Exception as e:
            cprint(f"Error authenticating from service account file: {e}", 'red')
            raise

    def chat(self, prompt_text, image_paths=None):
        # (æ­¤å‡½æ•°æ˜¯ Agent çš„æ ¸å¿ƒï¼Œè´Ÿè´£è°ƒç”¨ Gemini API)
        if image_paths is None:
            image_paths = []
            
        try:
            access_token = self._get_access_token()
        except Exception:
            return "Could not authenticate. Please check your service account credentials path and permissions."

        url = f"https://{self.config['location']}-aiplatform.googleapis.com/v1/projects/{self.config['project_id']}/locations/{self.config['location']}/publishers/google/models/{self.config['model_name']}:streamGenerateContent"
        headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}

        parts = [{"text": prompt_text}]
        valid_image_count = 0
        for image_path in image_paths:
            base64_image = encode_image_to_base64(image_path)
            if base64_image:
                parts.append({"inline_data": {"mime_type": "image/png", "data": base64_image}})
                valid_image_count += 1
        
        payload = {
            "system_instruction": self.system_instruction,
            "contents": [{"role": "user", "parts": parts}],
            "generationConfig": {"temperature": 0.0, "maxOutputTokens": 8192}
        }
        
        cprint(f"Agent '{self.role}' is sending request to {self.config['model_name']} with {valid_image_count} image(s)...", 'blue')

        try:
            response = requests.post(url, headers=headers, json=payload, proxies=self.proxies)
            if response.status_code != 200:
                cprint(f"API Error: {response.status_code}\nResponse: {response.text}", 'red')
                return f"API Error: Received status code {response.status_code}"
            
            response.raise_for_status()
            
            full_text_response = "".join(
                item['candidates'][0]['content']['parts'][0]['text']
                for item in response.json()
                if 'candidates' in item and 'content' in item['candidates'][0] and 'parts' in item['candidates'][0]['content']
            )
            
            if not full_text_response:
                cprint(f"Error: Response contained no text. Full Response: {response.json()}", 'red')
                return "Error: Model returned an empty response."

            return full_text_response

        except requests.exceptions.RequestException as e:
            cprint(f"Network error calling Vertex AI API: {e}", 'red')
            return f"Network Error: {e}"
        except Exception as e:
            cprint(f"An unknown error occurred while processing Vertex AI response: {e}", 'red')
            return f"Unknown Error: {e}"

# --- 4. å·¥ä½œæµå„é˜¶æ®µå‡½æ•° (Workflow Phase Functions) ---

def run_phase1_analysis(image_paths_ap, image_paths_dp, image_paths_pvp):
    # (æ­¤å‡½æ•°è´Ÿè´£æ‰§è¡Œç¬¬ä¸€é˜¶æ®µçš„çœŸå®VLLMè°ƒç”¨)
    cprint("\n--- [Phase 1: Parallel Feature Extraction with Professional Questions] ---", 'yellow', attrs=['bold'])

    # 1. ã€ã€æ–°æ•´åˆçš„ä»£ç ã€‘ã€‘å®šä¹‰ä¸“ä¸šçš„ç‰¹å¾åç§°å’Œå¯¹åº”çš„æè¿°é€‰é¡¹
    # (è¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨æå–äº†æ‚¨æ³¨é‡Šä¸­çš„ç‰¹å¾åç§°)
    feature_names = [
        "Enhancing Capsule",
        "Peritumoral Perfusion Alteration",
        "Corona Enhancement",
        "Fade Enhancement Pattern",
        "Nodule-in-Nodule Architecture",
        "Peripheral Washout",
        "Delayed Central Enhancement"
    ]

    questions_list_professional = [
        # --- 1. å¼ºåŒ–çš„åŒ…è†œ (Enhancing Capsule) ---
        # æ³¨é‡Š: ä¸€ä¸ªçœŸæ­£çš„å¼ºåŒ–åŒ…è†œï¼Œå…¶ç‰¹å¾åœ¨äºå®ƒåœ¨PVPæˆ–DPç›¸å¯¹äºAPçš„â€œå¼ºåŒ–â€è¡Œä¸ºã€‚å› æ­¤ï¼Œå¿…é¡»å¯¹æ¯”æœŸç›¸æ¥ç¡®è®¤ã€‚
        ['A distinct, hyper-enhancing rim is NOT identified in the PVP/DP, or any visible rim does not show clear enhancement compared to the AP.',
        'By comparing phases, a smooth rim is identified that enhances to become distinctly hyper-enhancing in the PVP or DP.'],

        # --- 2. ç˜¤å‘¨å¼‚å¸¸çŒæ³¨ (Peritumoral Perfusion Alteration) ---
        # æ³¨é‡Š: è¯¥ç‰¹å¾çš„æœ¬è´¨æ˜¯â€œä¸€è¿‡æ€§â€çš„ï¼Œå³æ¥å¾—å¿«å»å¾—ä¹Ÿå¿«ã€‚å› æ­¤ï¼Œå¿…é¡»é€šè¿‡APå’ŒPVPçš„å¯¹æ¯”æ¥ç¡®è®¤å…¶æ˜¯å¦â€œä¸€è¿‡æ€§â€ã€‚
        ['No clear perfusion anomalies are seen in the AP, or any observed hyperenhancement around the lesion persists into the PVP.',
        'A transient perfusion anomaly is confirmed: wedge-shaped or halo-like hyperenhancement is visible around the lesion in the AP and resolves (disappears) in the PVP.'],

        # --- 3. å† çŠ¶å¼ºåŒ– (Corona Enhancement) ---
        # æ³¨é‡Š: â€œå† çŠ¶å¼ºåŒ–â€æè¿°çš„æ˜¯ä¸€ç§åŠ¨æ€çš„è¡€æµç°è±¡ï¼Œè§‚å¯Ÿå®ƒåœ¨ä¸åŒæœŸç›¸çš„å‡ºç°å’Œæ¶ˆé€€æ‰èƒ½æœ€ç»ˆç¡®è®¤ã€‚
        ['No radiating vascular pattern is seen at the tumor periphery in any phase.',
        'A dynamic "corona enhancement" is identified: a radiating vascular pattern appears at the tumor periphery in the late AP or PVP and fades in later phases.'],

        # --- 4. "Fade" å¼ºåŒ–æ¨¡å¼ ---
        # æ³¨é‡Š: â€œFadeâ€æ¨¡å¼çš„å®šä¹‰æœ¬èº«å°±æ˜¯ä¸€ä¸ªè·¨è¶Šæ‰€æœ‰æœŸç›¸çš„æ¯”è¾ƒè¿‡ç¨‹ï¼Œä¸â€œWashoutâ€ç›¸å¯¹ã€‚
        ['Comparing across all phases, the lesion demonstrates a "washout" pattern, becoming hypodense in the PVP or DP.',
        'Comparing across all phases, the lesion demonstrates a "fade" pattern, with its enhancement in the delayed phase remaining similar to or greater than its enhancement in the AP/PVP.'],

        # --- 5. ç»“ä¸­ç»“æ¨¡å¼ (Nodule-in-Nodule Architecture) ---
        # æ³¨é‡Š: ç¡®è®¤â€œç»“ä¸­ç»“â€ä¸ä»…è¦çœ‹APæœŸçš„å½¢æ€ï¼Œè¿˜è¦çœ‹æ¯å­ç»“èŠ‚åœ¨PVPå’ŒDPçš„ä¸åŒåŠ¨æ€è¡Œä¸ºï¼ˆå¦‚å»“æ¸…ç¨‹åº¦ä¸åŒï¼‰ï¼Œæ‰èƒ½åšå‡ºæœ€å¯é çš„åˆ¤æ–­ã€‚
        ['Across all phases, the lesion\'s internal enhancement is either homogeneous or chaotically heterogeneous, lacking a clear, stable hierarchical structure.',
        'A "nodule-in-nodule" architecture is confirmed across phases: a smaller nodule shows more intense AP enhancement than the larger parent lesion, and this distinction often persists in later phases.'],

        # --- 6. ç˜¤å‘¨å»“æ¸… (Peripheral Washout) ---
        # æ³¨é‡Š: â€œå»“æ¸…â€æœ¬èº«å°±éœ€è¦APå’Œåç»­æœŸç›¸çš„å¯¹æ¯”ã€‚ç˜¤å‘¨å»“æ¸…æ˜¯ç‰¹æŒ‡è¿™ç§å¯¹æ¯”æ€§å‡ä½å‘ç”Ÿåœ¨è‚¿ç˜¤çš„è¾¹ç¼˜ã€‚
        ['After initial AP enhancement, the lesion either does not show washout or shows a non-peripheral (diffuse) washout pattern in the PVP/DP.',
        'After initial AP enhancement, the lesion shows a distinct "peripheral washout" pattern, with only its rim becoming hypoenhancing in the PVP/DP.'],

        # --- 7. å»¶è¿Ÿæ€§ä¸­å¿ƒå¼ºåŒ– (Delayed Central Enhancement) ---
        # æ³¨é‡Š: â€œå»¶è¿Ÿæ€§â€å’Œâ€œæ¸è¿›æ€§â€å¼ºåŒ–ï¼Œå…¶å®šä¹‰å°±æ˜¯åŸºäºå¯¹AP/PVPä¸DPä¸­å¿ƒåŒºåŸŸä¿¡å·å¼ºåº¦å˜åŒ–çš„æ¯”è¾ƒã€‚
        ['Comparing phases, the central part of the lesion does not show progressive enhancement (e.g., it washes out or remains persistently non-enhancing).',
        'Comparing phases, the central part of the lesion shows progressive, sustained enhancement, becoming brighter in the delayed phase than it was in the AP/PVP.']
    ]

    # 2. ã€ã€æ–°çš„Promptç”Ÿæˆé€»è¾‘ã€‘ã€‘åŠ¨æ€æ„å»ºé«˜çº§Prompt
    prompt_sections = []
    for i, name in enumerate(feature_names):
        option_0_desc = questions_list_professional[i][0]
        option_1_desc = questions_list_professional[i][1]
        prompt_sections.append(f"""
            --- Feature {i+1}: {name} ---
            Option 0 (Feature Absent): "{option_0_desc}"
            Option 1 (Feature Present): "{option_1_desc}"
            """)
    
    # æ„å»ºå®Œæ•´çš„ã€æ–°çš„Promptæ¨¡æ¿
    questions_prompt_template = f"""
You are a meticulous radiologist. Your task is to analyze a set of multi-phase CT images from a specific phase.
For each of the 7 features below, you are presented with two descriptive statements: Option 0 (first description) and Option 1 (second description).

Your tasks are:
1. Carefully analyze the provided images, comparing across different phases as needed.
2. For each feature, determine which option (0 or 1) most accurately describes the lesion.
3. Format your final output as a SINGLE, VALID JSON object. Do not add any explanatory text or markdown formatting outside of the JSON structure.

{''.join(prompt_sections)}

Your JSON output must follow this exact structure, containing all 7 features:
{{
  "Phase": "PHASE_ID",
  "findings": [
    {{"feature": "Enhancing Capsule", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}},
    {{"feature": "Peritumoral Perfusion Alteration", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}},
    {{"feature": "Corona Enhancement", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}},
    {{"feature": "Fade Enhancement Pattern", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}},
    {{"feature": "Nodule-in-Nodule Architecture", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}},
    {{"feature": "Peripheral Washout", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}},
    {{"feature": "Delayed Central Enhancement", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}}
  ]
}}
"""
    
    # 3. Agentåˆå§‹åŒ–å’Œè°ƒç”¨ (ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ)
    # ä¸ºåŠ¨è„‰æœŸ(AP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    ap_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze a set of CT images from the **Arterial Phase (AP)**.
    Your output will be a structured JSON report. **It is CRITICAL that your JSON is perfectly formatted and self-contained because it will be the direct input for other specialist AI analysts who will perform longitudinal and cross-sectional analysis. Their success depends entirely on the accuracy and clarity of your report.**
    You must answer all the specific questions provided below and format your output as a JSON object.
    Do not add any explanatory text outside of the JSON structure.
    For the 'value' key, use 0 for the first description or 1 for the second description.
    Provide a justification for your finding in the 'evidence' key.
    """

    # ä¸ºå»¶è¿ŸæœŸ(DP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    dp_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze a set of CT images from the **Delayed Phase (DP)**.
    Your output will be a structured JSON report. **It is CRITICAL that your JSON is perfectly formatted and self-contained because it will be the direct input for other specialist AI analysts who will perform longitudinal and cross-sectional analysis. Their success depends entirely on the accuracy and clarity of your report.**
    You must answer all the specific questions provided below and format your output as a JSON object.
    Do not add any explanatory text outside of the JSON structure.
    For the 'value' key, use 0 for the first description or 1 for the second description.
    Provide a justification for your finding in the 'evidence' key.
    """

    # ä¸ºé—¨è„‰æœŸ(PVP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    pvp_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze a set of CT images from the **Portal Venous Phase (PVP)**.
    Your output will be a structured JSON report. **It is CRITICAL that your JSON is perfectly formatted and self-contained because it will be the direct input for other specialist AI analysts who will perform longitudinal and cross-sectional analysis. Their success depends entirely on the accuracy and clarity of your report.**
    You must answer all the specific questions provided below and format your output as a JSON object.
    Do not add any explanatory text outside of the JSON structure.
    For the 'value' key, use 0 for the first description or 1 for the second description.
    Provide a justification for your finding in the 'evidence' key.
    """

    agent_1 = Agent(instruction=ap_analyst_instruction, role="phase AP Analyst")
    agent_2 = Agent(instruction=dp_analyst_instruction, role="phase DP Analyst")
    agent_3 = Agent(instruction=pvp_analyst_instruction, role="phase PVP Analyst")

    reports = {}
    for phase, paths in [("AP", image_paths_ap), ("DP", image_paths_dp), ("PVP", image_paths_pvp)]:
        cprint(f"Running analysis for phase {phase} with professional questions...", 'magenta')
        prompt = questions_prompt_template.replace("phase_ID", phase)
        # æ ¹æ®å½“å‰å¾ªç¯é€‰æ‹©å¯¹åº”çš„Agent
        if phase == 'AP':
            agent = agent_1
        elif phase == 'DP':
            agent = agent_2
        else:
            agent = agent_3
        
        response_text = agent.chat(prompt_text=prompt, image_paths=paths)
        
        try:
            # æ¸…ç†å¹¶è§£æJSON
            clean_json_text = response_text.strip().replace("```json", "").replace("```", "")
            reports[phase] = json.loads(clean_json_text)
            cprint(f"Successfully received and parsed JSON for Phase {phase}.", 'green')
        except (json.JSONDecodeError, AttributeError):
            cprint(f"Error: Failed to parse JSON from Phase {phase} Agent. Response:\n{response_text}", 'red')
            reports[phase] = {"error": "Failed to get a valid JSON response.", "raw_response": response_text}
        
        # print(f"phase1 output: {reports}")
            
    return reports

def run_phases_2_and_3(reports_from_phase1):
    # (æ­¤å‡½æ•°è´Ÿè´£æ‰§è¡Œç¬¬äºŒå’Œç¬¬ä¸‰é˜¶æ®µçš„æ–‡æœ¬åˆ†æ)
    cprint("\n" + "="*60, 'cyan')
    cprint("ğŸš€ Executing Phases 2 & 3 of the Workflow ğŸš€", 'cyan', attrs=['bold'])
    
    # æ£€æŸ¥ç¬¬ä¸€é˜¶æ®µæ˜¯å¦æœ‰é”™è¯¯
    if any("error" in r for r in reports_from_phase1.values()):
        cprint("Aborting Phases 2 and 3 due to errors in Phase 1.", 'red')
        return {"error": "Phase 1 failed.", "details": reports_from_phase1}
        
    cprint("="*60, 'cyan')
    cprint("\n--- [Phase 2: The Senior Analysis Committee] ---", 'yellow', attrs=['bold'])

    committee_input = f"""
    Below are three structured reports from phase Analysts regarding CT images from three different periods:
    [Report from phase AP]:
    {json.dumps(reports_from_phase1['AP'], indent=2, ensure_ascii=False)}
    [Report from phase DP]:
    {json.dumps(reports_from_phase1['DP'], indent=2, ensure_ascii=False)}
    [Report from phase PVP]:
    {json.dumps(reports_from_phase1['PVP'], indent=2, ensure_ascii=False)}
    """

    # Agent 4a: çºµå‘åˆ†æå¸ˆ
    longitudinal_analyst_prompt = """
    You are a senior radiologist acting as a **longitudinal analysis specialist** within an AI diagnostic committee.
    Your input consists of three structured reports generated by phase-specific AI analysts (AP, DP, PVP).
    Your sole task is to analyze these reports, focusing on the time dimension to summarize the evolution of each feature. Your output will be a concise, feature-centric evolution report **for the final Chief Radiologist**.
    It is important to highlight any inconsistencies in the findings between the different phase reports if they exist.
    """
    agent_4a = Agent(instruction=longitudinal_analyst_prompt, role="Longitudinal Analyst")
    longitudinal_report = agent_4a.chat(prompt_text=committee_input)
    cprint("--- Longitudinal Analyst Output ---", 'green')
    print(longitudinal_report)

    # Agent 4b: æ¨ªå‘åˆ†æå¸ˆ
    cross_sectional_analyst_prompt = """
    You are a senior radiologist acting as a **pattern recognition specialist** within an AI diagnostic committee.
    Your input consists of three structured reports generated by phase-specific AI analysts (AP, DP, PVP).
    Your sole task is to analyze these reports, focusing on each phase independently to provide a 'diagnostic snapshot'.
    Evaluate the combination of features present to determine the clinical picture for each phase. Your output will be a concise, timepoint-centric snapshot report **for the final Chief Radiologist**.
    """    
    agent_4b = Agent(instruction=cross_sectional_analyst_prompt, role="Cross-sectional Analyst")
    cross_sectional_report = agent_4b.chat(prompt_text=committee_input)
    cprint("--- Cross-sectional Analyst Output ---", 'green')
    print(cross_sectional_report)

    cprint("\n--- [Phase 3: Final Synthesized Diagnosis] ---", 'yellow', attrs=['bold'])
    
    synthesis_input = f"""
    [Feature Evolution Report from Longitudinal Analyst]:
    {longitudinal_report}
    [Diagnostic Snapshot Report from Cross-sectional Analyst]:
    {cross_sectional_report}
    """

    # Agent 5: é¦–å¸­æ•´åˆå®˜
    chief_synthesizer_prompt = """
    You are the **Chief Radiologist** presiding over an AI diagnostic committee. Your task is to provide the final, global conclusion.
    Your input consists of two expert summaries, which were generated by specialist AI analysts:
    1.  A **Feature Evolution Report** from the Longitudinal Analyst.
    2.  A **Diagnostic Snapshot Report** from the Cross-sectional Analyst.
    Your job is to **synthesize these two distinct perspectives** (the 'what changed over time' and the 'what is the pattern now') to form a single, coherent, final report.

    Your final output MUST be a single block of text that strictly follows the three-part structure outlined below. It is CRITICAL that you include the exact headings for each section, including the numbering.

    1.  **Core Conclusion:** 
        A concise paragraph summarizing the overall clinical findings and conclusion.

    2.  **Main Evidence:**
        Bulleted points detailing the key evidence from both the longitudinal and cross-sectional reports that support your core conclusion.

    3.  **Structured Summary:**
        This section MUST be a single, valid JSON object and nothing else. Do not add any introductory text, markdown tags like ```json, or any text after the JSON object.
        The JSON object must summarize the final answer for each of the 7 features. It must have keys from "pattern_1" to "pattern_7", corresponding to the features in this order:
        1. Enhancing Capsule
        2. Peritumoral Perfusion Alteration
        3. Corona Enhancement
        4. Fade Enhancement Pattern
        5. Nodule-in-Nodule Architecture
        6. Peripheral Washout
        7. Delayed Central Enhancement

        For each pattern, the value must be an object with two keys:
        - "answer": The final binary conclusion (0 for absent, 1 for present).
        - "justification": A brief, concise summary of the reasoning.

    Example of the required structure for the JSON part ONLY:
    {
        "pattern_1": { "answer": 0, "justification": "Consistently absent" },
        "pattern_2": { "answer": 1, "justification": "Appeared in PVP" }
    }
    """

    agent_5 = Agent(instruction=chief_synthesizer_prompt, role="Chief Synthesizer")
    final_hybrid_output = agent_5.chat(prompt_text=synthesis_input)
    
    # ã€ã€æ–°ã€‘ã€‘å¢åŠ è§£æé€»è¾‘ï¼Œåˆ†ç¦»æ–‡æœ¬æŠ¥å‘Šå’ŒJSONå¯¹è±¡
    prose_report = ""
    structured_summary = {}
    
    try:
        # æˆ‘ä»¬ä½¿ç”¨ "Structured Summary:" ä½œä¸ºåˆ†å‰²ç‚¹
        if "Structured Summary:" in final_hybrid_output:
            parts = final_hybrid_output.split("Structured Summary:", 1)
            prose_report = parts[0].strip()
            json_text = parts[1].strip()
            
            # æ¸…ç†å¹¶è§£æJSON
            clean_json_text = json_text.replace("```json", "").replace("```", "").strip()
            structured_summary = json.loads(clean_json_text)
        else:
            # å¦‚æœæ¨¡å‹æ²¡æœ‰æŒ‰é¢„æœŸè¾“å‡ºï¼Œåˆ™å°†å…¨éƒ¨å†…å®¹è§†ä¸ºæ–‡æœ¬æŠ¥å‘Š
            prose_report = final_hybrid_output
            structured_summary = {"error": "Structured Summary section not found in the output."}

    except Exception as e:
        cprint(f"Error parsing hybrid output from Chief Synthesizer: {e}", "red")
        prose_report = final_hybrid_output # ä¿ç•™åŸå§‹è¾“å‡ºä»¥ä¾›è°ƒè¯•
        structured_summary = {"error": f"Failed to parse JSON part. Details: {e}"}

    # è¿”å›ä¸¤ä¸ªéƒ¨åˆ†ï¼šæ–‡æœ¬æŠ¥å‘Šå’Œç»“æ„åŒ–å­—å…¸
    return prose_report, structured_summary

# --- 5. ä¸»æ‰§è¡Œé€»è¾‘ (Main Execution Logic) ---

def main():
    # (è¿™æ˜¯ä¸»å‡½æ•°ï¼Œè´Ÿè´£ç¼–æ’æ•´ä¸ªæµç¨‹)
    all_patient_results = {}

    try:
        patient_ids = [d for d in os.listdir(BASE_DATA_PATH) if os.path.isdir(os.path.join(BASE_DATA_PATH, d))]
        patient_ids.sort()
        if not patient_ids:
            cprint(f"Error: No patient folders found in '{BASE_DATA_PATH}'.", 'red')
            return
        cprint(f"Found {len(patient_ids)} patient folder(s). Starting processing...", 'cyan', attrs=['bold'])
    except FileNotFoundError:
        cprint(f"Error: The directory '{BASE_DATA_PATH}' was not found. Please check the path.", 'red')
        return

    for patient_id in tqdm(patient_ids, desc="Processing Patients"):
        cprint(f"\n{'='*20} Processing Patient: {patient_id} {'='*20}", 'yellow')
        patient_folder = os.path.join(BASE_DATA_PATH, patient_id)
        
        # ä¸ºæ¯ä¸ªæ—¶æœŸæ”¶é›†å›¾åƒè·¯å¾„
        image_paths_ap = sorted([os.path.join(patient_folder, 'AP', f) for f in os.listdir(os.path.join(patient_folder, 'AP')) if f.endswith('.png')])
        image_paths_dp = sorted([os.path.join(patient_folder, 'DP', f) for f in os.listdir(os.path.join(patient_folder, 'DP')) if f.endswith('.png')])
        image_paths_pvp = sorted([os.path.join(patient_folder, 'PVP', f) for f in os.listdir(os.path.join(patient_folder, 'PVP')) if f.endswith('.png')])
        
        if not all([image_paths_ap, image_paths_dp, image_paths_pvp]):
            cprint(f"Warning: Patient {patient_id} is missing images in one or more phase folders. Skipping.", 'red')
            continue

        # æ‰§è¡Œç¬¬ä¸€é˜¶æ®µ
        phase1_reports = run_phase1_analysis(image_paths_ap, image_paths_dp, image_paths_pvp)
        print(f"phase1 reports: {phase1_reports}")
        
        # æ‰§è¡Œç¬¬äºŒå’Œç¬¬ä¸‰é˜¶æ®µ
        prose_report, structured_summary = run_phases_2_and_3(phase1_reports)

        
        # æ”¶é›†ç»“æœ
        all_patient_results[patient_id] = structured_summary

        cprint(f"\n--- Final Hybrid Report for Patient {patient_id} ---", 'cyan', attrs=['bold'])
        print("--- Prose Report ---")
        print(prose_report)
        print("\n--- Structured Summary (JSON) ---")
        print(json.dumps(structured_summary, indent=4, ensure_ascii=False))

    # å°†æ‰€æœ‰ç—…äººçš„ç»“æœä¿å­˜åˆ°ä¸€ä¸ªJSONæ–‡ä»¶ä¸­
    output_filename = "multi_agent_results.json"
    with open(output_filename, 'w', encoding='utf-8') as f:
        json.dump(all_patient_results, f, ensure_ascii=False, indent=4)
    
    cprint(f"\n\nğŸ‰ All processing complete. All reports have been saved to '{output_filename}'.", 'cyan', attrs=['bold'])


if __name__ == '__main__':
    main()
