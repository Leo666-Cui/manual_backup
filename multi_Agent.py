import os
import json
import base64
import requests
from tqdm import tqdm
from termcolor import cprint
import google.auth
import google.auth.transport.requests
from google.oauth2 import service_account
import re
import json
from concurrent.futures import ThreadPoolExecutor


# --- 1. é…ç½®åŒº (Configuration Section) ---
# è¯·åœ¨æ­¤å¤„ä¿®æ”¹æ‚¨çš„ä¸ªäººé…ç½®

# é¡¹ç›®å’Œæ¨¡å‹é…ç½®
VERTEX_AI_CONFIG = {
    "project_id": "gen-lang-client-0514315738",
    "location": "us-central1",
    # ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘è¯·åŠ¡å¿…ä¿®æ”¹ä¸ºæ‚¨çš„æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶çš„çœŸå®è·¯å¾„
    "credentials_path": "/home/yxcui/FM-Bridge/testing_file/gen-lang-client-0514315738-faeaf04b384e.json",
    "model_name": "gemini-2.5-pro"  # gemini-2.5-flash
}

# ä»£ç†é…ç½®
PROXY_CONFIG = {
    # å¦‚æœæ‚¨ä¸éœ€è¦ä»£ç†ï¼Œè¯·å°†æ­¤è¡Œè®¾ç½®ä¸º None, ä¾‹å¦‚ï¼š'https': None
    'https': 'socks5://hkumedai:bestpaper@66.42.72.8:54321' 
}

# ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘è¯·ä¿®æ”¹ä¸ºæ‚¨çš„æ•°æ®é›†æ ¹ç›®å½•
BASE_DATA_PATH = "/home/yxcui/FM-Bridge/testing_file/test_dataset/cropped_30_slices_image"


# è§„åˆ™ï¼šå®šä¹‰æ¯ä¸ªç‰¹å¾æœ€ç»ˆè¯Šæ–­æ‰€å¿…éœ€çš„æœŸç›¸
FEATURE_PHASE_REQUIREMENTS = {
    "Enhancing Capsule": ["AP", "PVP", "DP"], # 44
    "Peritumoral Perfusion Alteration": ["AP", "PVP"], # 53
    "Peritumoral Hypodense Halo": ["PVP", "DP"], # 59
    "Corona Enhancement": ["AP", "PVP", "DP"], # 60
    "Custom TTPVI Feature": ["AP", "PVP", "DP"], # 62 
    "Fade Enhancement Pattern": ["AP", "PVP", "DP"], # 65
    "Nodule-in-Nodule Architecture": ["AP", "PVP", "DP"], # 66
    "Peripheral Washout": ["AP", "PVP", "DP"], # 68
    "Delayed Central Enhancement": ["AP", "DP"] # 70
}

# --- ä¸´åºŠé—®é¢˜å®šä¹‰ (Clinical Question Definitions) ---
# å°†é—®é¢˜åˆ—è¡¨å®šä¹‰ä¸ºå…¨å±€å¸¸é‡ï¼Œä¾›æ‰€æœ‰Agentè®¿é—®
FEATURE_DEFINITIONS = [
    {
        "name": "Enhancing Capsule", # 44
        "options": [
            'A distinct, hyper-enhancing rim is NOT identified in the PVP/DP, or any visible rim does not show clear enhancement compared to the AP.',
            'By comparing phases, a smooth rim is identified that enhances to become distinctly hyper-enhancing in the PVP or DP.'
        ]
    },
    {
        "name": "Peritumoral Perfusion Alteration", # 53
        "options": [
            'No clear perfusion anomalies are seen in the AP, or any observed hyperenhancement around the lesion persists into the PVP.',
            'A transient perfusion anomaly is confirmed: wedge-shaped or halo-like hyperenhancement is visible around the lesion in the AP and resolves (disappears) in the PVP.'
        ]
    },
    {
        "name": "Peritumoral Hypodense Halo", # 59
        "options": [
            'In the PVP or DP, the interface between the lesion and the surrounding liver parenchyma is direct, without a distinct, dark, intervening ring.',
            'In the PVP or DP, a distinct, dark (hypodense), well-defined ring is visible immediately surrounding the exterior of the lesion. This "halo" is darker than both the lesion\'s periphery and the adjacent liver tissue.'
        ]
    },
    {
        "name": "Corona Enhancement", # 60
        "options": [
            'No radiating vascular pattern is seen at the tumor periphery in any phase.',
            'A dynamic "corona enhancement" is identified: a radiating vascular pattern appears at the tumor periphery in the late AP or PVP and fades in later phases.'
        ]
    },
    {
        "name": "Custom TTPVI Feature", # 62
        "options": [
            'The combined pattern is ABSENT. This condition is met if the AP analysis fails to show distinct intratumoral arteries, OR if the PVP/DP analysis reveals the presence of a peritumoral hypodense halo.',
            'The combined pattern is PRESENT. This requires a two-step confirmation: 1) The AP analysis must show distinct, dot-like or linear hyper-enhancing structures (intratumoral arteries) inside the lesion, AND 2) The PVP/DP analysis must confirm the absence of a peritumoral hypodense halo.'
        ]
    },
    {
        "name": "Fade Enhancement Pattern", # 65
        "options": [
            'Comparing phases, the lesion becomes hypodense relative to surrounding liver in the PVP or DP, demonstrating a "washout" pattern.',
            'Comparing phases, the lesion enhancement persists, remaining iso- or hyper-enhancing relative to surrounding liver in the PVP or DP, demonstrating a "fade" (non-washout) pattern.'
        ]
    },
    {
        "name": "Nodule-in-Nodule Architecture", # 66
        "options": [
            'Across all phases, the lesion\'s internal enhancement is either homogeneous or chaotically heterogeneous, lacking a clear, stable hierarchical structure.',
            'A "nodule-in-nodule" architecture is confirmed across phases: a smaller nodule shows more intense AP enhancement than the larger parent lesion, and this distinction often persists in later phases.'
        ]
    },
    {
        "name": "Peripheral Washout", # 68
        "options": [
            'After initial AP enhancement, the lesion either does not show washout or shows a non-peripheral (diffuse) washout pattern in the PVP/DP.',
            'After initial AP enhancement, the lesion shows a distinct "peripheral washout" pattern, with only its rim becoming hypoenhancing in the PVP/DP.'
        ]
    },
    {
        "name": "Delayed Central Enhancement", # 70
        "options": [
            'Comparing phases, the central part of the lesion does not show progressive enhancement (e.g., it washes out or remains persistently non-enhancing).',
            'Comparing phases, the central part of the lesion shows progressive, sustained enhancement, becoming brighter in the delayed phase than it was in the AP.'
        ]
    }
]


# --- 2. è¾…åŠ©å‡½æ•° (Helper Functions) ---

def encode_image_to_base64(image_path):
    # (æ­¤å‡½æ•°ç”¨äºå°†å›¾ç‰‡ç¼–ç ä¸ºBase64)
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError:
        cprint(f"Warning: Image file not found at {image_path}. Skipping.", 'red')
        return None

# --- 3. æ™ºèƒ½ä½“æ ¸å¿ƒç±» (Agent Core Class) ---

class Agent:
    def __init__(self, instruction, role):
        # (æ­¤å¤„çš„ Agent ç±»ä¸æˆ‘ä»¬ä¹‹å‰ç‰ˆæœ¬ç›¸åŒï¼Œä½¿ç”¨ Gemini API)
        self.system_instruction = {"parts": [{"text": instruction}]}
        self.role = role
        self.config = VERTEX_AI_CONFIG
        self.proxies = PROXY_CONFIG if PROXY_CONFIG.get('https') else None

    def _get_access_token(self):
        # (æ­¤å‡½æ•°ç”¨äºé€šè¿‡æœåŠ¡è´¦å·è·å–è®¿é—®ä»¤ç‰Œ)
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.config['credentials_path'],
                scopes=['https://www.googleapis.com/auth/cloud-platform']
            )
            auth_req = google.auth.transport.requests.Request()
            credentials.refresh(auth_req)
            return credentials.token
        except Exception as e:
            cprint(f"Error authenticating from service account file: {e}", 'red')
            raise

    def chat(self, prompt_text, image_paths=None):
        # (æ­¤å‡½æ•°æ˜¯ Agent çš„æ ¸å¿ƒï¼Œè´Ÿè´£è°ƒç”¨ Gemini API)
        if image_paths is None:
            image_paths = []
            
        try:
            access_token = self._get_access_token()
        except Exception:
            return "Could not authenticate. Please check your service account credentials path and permissions."

        url = f"https://{self.config['location']}-aiplatform.googleapis.com/v1/projects/{self.config['project_id']}/locations/{self.config['location']}/publishers/google/models/{self.config['model_name']}:streamGenerateContent"
        headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}

        parts = [{"text": prompt_text}]
        valid_image_count = 0
        for image_path in image_paths:
            base64_image = encode_image_to_base64(image_path)
            if base64_image:
                parts.append({"inline_data": {"mime_type": "image/png", "data": base64_image}})
                valid_image_count += 1
        
        payload = {
            "system_instruction": self.system_instruction,
            "contents": [{"role": "user", "parts": parts}],
            "generationConfig": {"temperature": 0.0, "maxOutputTokens": 8192}
        }
        
        cprint(f" Agent '{self.role}' is sending request to {self.config['model_name']} with {valid_image_count} image(s)...", 'blue')

        try:
            response = requests.post(url, headers=headers, json=payload, proxies=self.proxies)
            if response.status_code != 200:
                cprint(f"API Error: {response.status_code}\nResponse: {response.text}", 'red')
                return f"API Error: Received status code {response.status_code}"
            
            response.raise_for_status()
            
            full_text_response = "".join(
                item['candidates'][0]['content']['parts'][0]['text']
                for item in response.json()
                if 'candidates' in item and 'content' in item['candidates'][0] and 'parts' in item['candidates'][0]['content']
            )
            
            if not full_text_response:
                cprint(f"Error: Response contained no text. Full Response: {response.json()}", 'red')
                return "Error: Model returned an empty response."

            return full_text_response

        except requests.exceptions.RequestException as e:
            cprint(f"Network error calling Vertex AI API: {e}", 'red')
            return f"Network Error: {e}"
        except Exception as e:
            cprint(f"An unknown error occurred while processing Vertex AI response: {e}", 'red')
            return f"Unknown Error: {e}"




# --- 4. å·¥ä½œæµå„é˜¶æ®µå‡½æ•° (Workflow Phase Functions) ---

def find_core_slice(image_paths_pvp: list):
    """
    ä½¿ç”¨ä¸¤é˜¶æ®µAIæµç¨‹ï¼Œä»ä¸€ä¸ªæœŸç›¸çš„å›¾ç‰‡åˆ—è¡¨ä¸­æ™ºèƒ½é€‰å‡ºâ€œæ ¸å¿ƒåˆ‡ç‰‡â€ã€‚
    
    :param image_paths_pvp: PVPæœŸç›¸çš„10å¼ å›¾ç‰‡è·¯å¾„åˆ—è¡¨ã€‚
    :return: é€‰å‡ºçš„æ ¸å¿ƒåˆ‡ç‰‡å·ç  (int)ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    cprint("\n--- [å¯åŠ¨æ ¸å¿ƒåˆ‡ç‰‡æ™ºèƒ½ç­›é€‰å­æµç¨‹] ---", 'blue', attrs=['bold'])

    # --- åˆå§‹åŒ–æœ¬æµç¨‹æ‰€éœ€çš„Agent ---
    
    # 1a. åˆ‡ç‰‡è¯„åˆ†å‘˜ (Slice Scorer)
    slice_scorer_instruction = """
    You are a radiologist assistant. Your task is to evaluate a single CT slice and provide scores for its diagnostic quality.
    Based on the single image provided, please rate the following three criteria on a scale of 1 (very poor) to 10 (excellent).
    Your output must be a single, valid JSON object with no other text.
    1.  Lesion Size Score: How large is the lesion in this slice?
    2.  Border Clarity Score: How clear and well-defined is the lesion's border?
    3.  Feature Conspicuousness Score: How clearly are features visible?
    """
    slice_scorer_agent = Agent(instruction=slice_scorer_instruction, role="Slice Scorer")

    # 1b. ç”„é€‰å†³ç­–å®˜ (Selection Judge)
    selection_judge_instruction = """
    You are a senior radiologist. You have been provided with scorecards for multiple CT slices.
    Your task is to select the single best 'Core Slice' by weighing all scores, with a slight priority for 'Border Clarity' and 'Feature Conspicuousness'.
    Your final output must be a single number representing the chosen slice number, inside a JSON object.
    """
    selection_judge_agent = Agent(instruction=selection_judge_instruction, role="Selection Judge")

    # --- é˜¶æ®µä¸€ï¼šå¹¶è¡Œè¯„åˆ† (â€œæµ·é€‰â€) ---
    scorecards = []
    cprint("--- [æµ·é€‰é˜¶æ®µ] å¼€å§‹å¯¹PVPåˆ‡ç‰‡è¿›è¡Œè¯„åˆ†...", 'blue')
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œçš„å¾ªç¯å¯ä»¥ä½¿ç”¨ threading æˆ– asyncio å®ç°çœŸæ­£çš„å¹¶è¡Œå¤„ç†
    for image_path in tqdm(image_paths_pvp, desc="Scoring PVP Slices"):
        
        # ä»æ–‡ä»¶åä¸­æå–åˆ‡ç‰‡å·
        slice_number = None
        match = re.search(r'(\d+)\.png$', image_path)
        if match:
            slice_number = int(match.group(1))
        
        if slice_number is None:
            cprint(f"Warning: Could not extract slice number from '{image_path}'. Skipping.", 'yellow')
            continue

        # ä¸ºè¯„åˆ†å‘˜æ„å»ºä¸“å±ä»»åŠ¡Prompt
        scorer_task_prompt = f"""
        Please evaluate the provided CT slice and output your scores in the required JSON format.
        This is slice number {slice_number}.

        REQUIRED JSON OUTPUT FORMAT:
        {{
            "slice_number": {slice_number},
            "size_score": "[Your score from 1-10]",
            "border_score": "[Your score from 1-10]",
            "feature_score": "[Your score from 1-10]"
        }}
        """
        
        # è°ƒç”¨è¯„åˆ†å‘˜Agentï¼Œæ³¨æ„image_pathsæ˜¯ä¸€ä¸ªåªåŒ…å«å•å¼ å›¾ç‰‡çš„åˆ—è¡¨
        response_text = slice_scorer_agent.chat(prompt_text=scorer_task_prompt, image_paths=[image_path])
        
        # è§£æè¯„åˆ†ç»“æœ
        try:
            clean_json_text = response_text.strip().replace("```json", "").replace("```", "")
            scorecard = json.loads(clean_json_text)
            scorecards.append(scorecard)
        except (json.JSONDecodeError, AttributeError):
            cprint(f"Error: Failed to parse JSON from Slice Scorer for '{image_path}'. Response:\n{response_text}", 'red')
    # print(f"scorecards: \n{scorecards}\n")

    # --- é˜¶æ®µäºŒï¼šç»¼åˆå†³ç­– (â€œå†³é€‰â€) ---
    if not scorecards:
        cprint("Error: No valid scorecards were generated in the scoring phase. Cannot determine core slice.", 'red')
        return None

    cprint("\n--- [å†³é€‰é˜¶æ®µ] å¼€å§‹æ ¹æ®è¯„åˆ†é€‰æ‹©æ ¸å¿ƒåˆ‡ç‰‡...", 'blue')
    
    # ä¸ºå†³ç­–å®˜å‡†å¤‡è¾“å…¥
    judge_task_prompt = f"""
    Here are the scorecards for {len(scorecards)} different CT slices. Please select the single best 'Core Slice' number.

    **Scorecards:**
    {json.dumps(scorecards, indent=2)}

    **REQUIRED JSON OUTPUT FORMAT:**
    {{
        "core_slice_number": [The number of the slice you selected]
    }}
    """
    
    # è°ƒç”¨å†³ç­–å®˜Agent
    response_text = selection_judge_agent.chat(prompt_text=judge_task_prompt)
    
    # è§£ææœ€ç»ˆå†³ç­–
    try:
        clean_json_text = response_text.strip().replace("```json", "").replace("```", "")
        decision = json.loads(clean_json_text)
        core_slice_number = int(decision["core_slice_number"])
        cprint(f"âœ… AI has selected Core Slice Number: {core_slice_number}", 'green', attrs=['bold'])
        return core_slice_number
    except (json.JSONDecodeError, KeyError, ValueError) as e:
        cprint(f"Error: Failed to parse JSON from Selection Judge. Error: {e}. Response:\n{response_text}", 'red')
        return None


def select_final_slices(core_slice_num, image_paths_ap, image_paths_dp, image_paths_pvp):
    """
    æ ¹æ®AIé€‰å‡ºçš„æ ¸å¿ƒåˆ‡ç‰‡å·ç ï¼Œæ™ºèƒ½åœ°ä»æ¯ä¸ªæœŸç›¸ä¸­é€‰æ‹©ä¸‰å¼ ä»£è¡¨æ€§åˆ‡ç‰‡ã€‚
    - å¦‚æœæ ¸å¿ƒåˆ‡ç‰‡æ˜¯ç¬¬ä¸€å¼ ï¼Œåˆ™é€‰æ‹©å‰ä¸‰å¼ ã€‚
    - å¦‚æœæ ¸å¿ƒåˆ‡ç‰‡æ˜¯æœ€åä¸€å¼ ï¼Œåˆ™é€‰æ‹©æœ€åä¸‰å¼ ã€‚
    - å¦åˆ™ï¼Œé€‰æ‹©æ ¸å¿ƒåˆ‡ç‰‡åŠå…¶å‰åä¸¤å¼ ã€‚

    :param core_slice_num: AIé€‰å‡ºçš„æ ¸å¿ƒåˆ‡ç‰‡å·ç  (int)ã€‚
    :param image_paths_ap, dp, pvp: ä¸‰ä¸ªæœŸç›¸çš„å®Œæ•´å›¾ç‰‡è·¯å¾„åˆ—è¡¨ã€‚
    :return: ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªåˆ—è¡¨çš„å…ƒç»„ (selected_ap, selected_dp, selected_pvp)ã€‚
    """
    # cprint(f"Core slice {core_slice_num} selected. Selecting adjacent slices based on file order...", 'cyan')

    # --- æ­¥éª¤ 1: åœ¨PVPåˆ—è¡¨ä¸­æ‰¾åˆ°æ ¸å¿ƒåˆ‡ç‰‡çš„ç´¢å¼•ä½ç½® ---
    # æˆ‘ä»¬ä»¥PVPä½œä¸ºå®šä½åŸºå‡†
    core_slice_index = -1
    
    # é¦–å…ˆï¼Œè§£ææ‰€æœ‰PVPè·¯å¾„ä»¥è·å–å·ç å’Œç´¢å¼•çš„æ˜ å°„
    pvp_slice_numbers = []
    for path in image_paths_pvp:
        match = re.search(r'(\d+)\.png$', path)
        if match:
            pvp_slice_numbers.append(int(match.group(1)))
        else:
            pvp_slice_numbers.append(-1) # æ·»åŠ ä¸€ä¸ªæ— æ•ˆå€¼ä»¥ä¿æŒç´¢å¼•å¯¹åº”

    try:
        # æ‰¾åˆ°æ ¸å¿ƒå·ç åœ¨å·ç åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹çš„ç´¢å¼•
        core_slice_index = pvp_slice_numbers.index(core_slice_num)
    except ValueError:
        cprint(f"Error: Could not find the core slice number {core_slice_num} in the PVP image list. Skipping.", 'red')
        return None, None, None

    # --- æ­¥éª¤ 2: æ ¹æ®æ‚¨çš„æ–°è§„åˆ™ï¼Œç¡®å®šæœ€ç»ˆçš„åˆ‡ç‰‡çª—å£ç´¢å¼• ---
    num_images = len(image_paths_pvp)
    
    if core_slice_index == 0:
        # å¦‚æœæ ¸å¿ƒåˆ‡ç‰‡æ˜¯ç¬¬ä¸€å¼ ï¼Œé€‰æ‹©å‰ä¸‰å¼ 
        start_index = 0
        end_index = 3
        cprint("Core slice is the first slice. Selecting the first three.", "blue")
    elif core_slice_index == num_images - 1:
        # å¦‚æœæ ¸å¿ƒåˆ‡ç‰‡æ˜¯æœ€åä¸€å¼ ï¼Œé€‰æ‹©æœ€åä¸‰å¼ 
        start_index = num_images - 3
        end_index = num_images
        cprint("Core slice is the last slice. Selecting the last three.", "blue")
    else:
        # å¦åˆ™ï¼Œé€‰æ‹©æ ¸å¿ƒåˆ‡ç‰‡åŠå…¶é‚»å±…
        start_index = core_slice_index - 1
        end_index = core_slice_index + 2
        cprint("Core slice is in the middle. Selecting adjacent three.", "blue")
    
    # å†æ¬¡ç¡®ä¿ç´¢å¼•ä¸ä¼šå› åˆ—è¡¨å¤ªçŸ­è€Œå‡ºé”™
    start_index = max(0, start_index)
    end_index = min(num_images, end_index)


    # --- æ­¥éª¤ 3: å°†è¿™ä¸ªå®‰å…¨çš„ç´¢å¼•èŒƒå›´ï¼Œç»Ÿä¸€åº”ç”¨åˆ°æ‰€æœ‰ä¸‰ä¸ªæœŸç›¸çš„åˆ—è¡¨ä¸Š ---
    selected_paths_ap = image_paths_ap[start_index:end_index]
    selected_paths_dp = image_paths_dp[start_index:end_index]
    selected_paths_pvp = image_paths_pvp[start_index:end_index]

    cprint(f"Selected AP slices: {[os.path.basename(p) for p in selected_paths_ap]}", 'cyan')
    cprint(f"Selected DP slices: {[os.path.basename(p) for p in selected_paths_dp]}", 'cyan')
    cprint(f"Selected PVP slices: {[os.path.basename(p) for p in selected_paths_pvp]}", 'cyan')

    return selected_paths_ap, selected_paths_dp, selected_paths_pvp

def run_phase_1(image_paths_ap, image_paths_dp, image_paths_pvp):
    cprint("\n--- [Phase 1: Parallel Feature Extraction with Professional Questions] ---", 'yellow', attrs=['bold'])
    
    # 3. Agentåˆå§‹åŒ–å’Œè°ƒç”¨ 
    # ä¸ºåŠ¨è„‰æœŸ(AP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    ap_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze a set of CT images from the **Arterial Phase (AP)**.
    Your output will be a structured JSON report. **It is CRITICAL that your JSON is perfectly formatted and self-contained because it will be the direct input for other specialist AI analysts who will perform longitudinal and cross-sectional analysis. Their success depends entirely on the accuracy and clarity of your report.**
    You must answer all the specific questions provided below and format your output as a JSON object.
    Do not add any explanatory text outside of the JSON structure.
    For the 'value' key, use 0 for the first description or 1 for the second description.
    Provide a justification for your finding in the 'evidence' key.
    """

    # ä¸ºå»¶è¿ŸæœŸ(DP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    dp_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze a set of CT images from the **Delayed Phase (DP)**.
    Your output will be a structured JSON report. **It is CRITICAL that your JSON is perfectly formatted and self-contained because it will be the direct input for other specialist AI analysts who will perform longitudinal and cross-sectional analysis. Their success depends entirely on the accuracy and clarity of your report.**
    You must answer all the specific questions provided below and format your output as a JSON object.
    Do not add any explanatory text outside of the JSON structure.
    For the 'value' key, use 0 for the first description or 1 for the second description.
    Provide a justification for your finding in the 'evidence' key.
    """

    # ä¸ºé—¨è„‰æœŸ(PVP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    pvp_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze a set of CT images from the **Portal Venous Phase (PVP)**.
    Your output will be a structured JSON report. **It is CRITICAL that your JSON is perfectly formatted and self-contained because it will be the direct input for other specialist AI analysts who will perform longitudinal and cross-sectional analysis. Their success depends entirely on the accuracy and clarity of your report.**
    You must answer all the specific questions provided below and format your output as a JSON object.
    Do not add any explanatory text outside of the JSON structure.
    For the 'value' key, use 0 for the first description or 1 for the second description.
    Provide a justification for your finding in the 'evidence' key.
    """

    agent_1 = Agent(instruction=ap_analyst_instruction, role="phase AP Analyst")
    agent_2 = Agent(instruction=dp_analyst_instruction, role="phase DP Analyst")
    agent_3 = Agent(instruction=pvp_analyst_instruction, role="phase PVP Analyst")

    reports = {}
    for phase, paths, agent in [("AP", image_paths_ap, agent_1), ("DP", image_paths_dp, agent_2), ("PVP", image_paths_pvp, agent_3)]:
        
        # 1. ã€ã€æ ¸å¿ƒé€»è¾‘ã€‘ã€‘ä¸ºå½“å‰æœŸç›¸ç­›é€‰ç›¸å…³é—®é¢˜
        questions_for_this_phase = []
        for feature in FEATURE_DEFINITIONS:
            # æŸ¥è¯¢çŸ¥è¯†åº“ï¼Œçœ‹å½“å‰ç‰¹å¾æ˜¯å¦éœ€è¦æœ¬æœŸç›¸
            if phase in FEATURE_PHASE_REQUIREMENTS.get(feature['name'], []):
                questions_for_this_phase.append(feature)

        if not questions_for_this_phase:
            cprint(f"No relevant questions for phase {phase}. Skipping agent call.", 'yellow')
            # ä¸ºè¯¥æœŸç›¸åˆ›å»ºä¸€ä¸ªç©ºçš„æŠ¥å‘Š
            reports[phase] = {"phase": phase, "findings": []}
            continue

        cprint(f"Running analysis for phase {phase}. Asking {len(questions_for_this_phase)} relevant question(s)...", 'magenta')

        # 2. åŠ¨æ€æ„å»ºåªåŒ…å«ç›¸å…³é—®é¢˜çš„é«˜çº§Prompt
        prompt_sections = []
        json_findings_template = []
        for i, feature in enumerate(questions_for_this_phase):
            prompt_sections.append(f"""
--- Feature {i+1}: {feature['name']} ---
Option 0 : "{feature['options'][0]}"
Option 1 : "{feature['options'][1]}"
""")
            json_findings_template.append(
                f'{{"feature": "{feature["name"]}", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}}'
            )

        # æ„å»ºå®Œæ•´çš„ã€æ–°çš„Promptæ¨¡æ¿
        questions_prompt_template = f"""
You are a meticulous radiologist analyzing images from the {phase} phase.
For each of the {len(questions_for_this_phase)} features below, you are presented with two descriptive statements.
Your task is to analyze the provided images and determine which option (0 or 1) is most accurate for each feature.
Format your final output as a SINGLE, VALID JSON object.
{''.join(prompt_sections)}
Your JSON output must follow this exact structure:
{{
  "phase": "{phase}",
  "findings": [
    {', '.join(json_findings_template)}
  ]
}}
"""
        response_text = agent.chat(prompt_text=questions_prompt_template, image_paths=paths)
        try:
            # æ¸…ç†å¹¶è§£æJSON
            clean_json_text = response_text.strip().replace("```json", "").replace("```", "")
            reports[phase] = json.loads(clean_json_text)
            cprint(f"Successfully received and parsed JSON for Phase {phase}.", 'green')
        except (json.JSONDecodeError, AttributeError):
            cprint(f"Error: Failed to parse JSON from Phase {phase} Agent. Response:\n{response_text}", 'red')
            reports[phase] = {"error": "Failed to get a valid JSON response.", "raw_response": response_text}
        
    # print(f"phase_1 output: {reports}")
    return reports


def run_phase_2(reports_from_phase1):
    # (æ­¤å‡½æ•°è´Ÿè´£æ‰§è¡Œç¬¬äºŒå’Œç¬¬ä¸‰é˜¶æ®µçš„æ–‡æœ¬åˆ†æ)
    cprint("\n" + "="*60, 'cyan')
    cprint("ğŸš€ Executing Phases 2 of the Workflow ğŸš€", 'cyan', attrs=['bold'])
    
    # æ£€æŸ¥ç¬¬ä¸€é˜¶æ®µæ˜¯å¦æœ‰é”™è¯¯
    if any("error" in r for r in reports_from_phase1.values()):
        cprint("Aborting Phases 2 due to errors in Phase 1.", 'red')
        return {"error": "Phase 1 failed.", "details": reports_from_phase1}
        
    cprint("="*60, 'cyan')
    cprint("\n--- [Phase 2: The Senior Analysis Committee] ---", 'yellow', attrs=['bold'])

    committee_input = f"""
    Below are three structured reports from phase Analysts regarding CT images from three different periods:
    [Report from phase AP]:
    {json.dumps(reports_from_phase1['AP'], indent=2, ensure_ascii=False)}
    [Report from phase DP]:
    {json.dumps(reports_from_phase1['DP'], indent=2, ensure_ascii=False)}
    [Report from phase PVP]:
    {json.dumps(reports_from_phase1['PVP'], indent=2, ensure_ascii=False)}
    """

    # Agent 4a: çºµå‘åˆ†æå¸ˆï¼šæ¯ä¸ªé—®é¢˜åœ¨ä¸‰ä¸ªæ—¶æœŸçš„å˜åŒ–
    longitudinal_analyst_prompt = """
    You are a senior radiologist acting as a **cross-phase analysis specialist** within an AI diagnostic committee.
    Your input consists of three **partial, phase-specific reports** from AI analysts (AP, DP, PVP). A report for a given phase will only contain findings for features observable in that phase. 

    Your task is to **synthesize these partial reports to create a complete evolutionary summary for all 9 features**.
    For any given feature, you may only have input from one, two, or all three reports; this is expected. You must deduce the overall evolution based on the available information. For example, to determine "Peritumoral Perfusion Alteration", you should primarily rely on the AP and PVP reports. 

    **IMPORTANT: Do not include any headers, titles, salutations, or conversational text like 'To:', 'From:', or 'Subject:'.**
    Your output will be a concise, feature-centric evolution report for the final Chief Radiologist. It is important to highlight any inconsistencies in the findings if they exist.
    """
    agent_4a = Agent(instruction=longitudinal_analyst_prompt, role="Longitudinal Analyst")

    # Agent 4b: æ¨ªå‘åˆ†æå¸ˆï¼šæ¯ä¸ªæ—¶æœŸæ‰€æœ‰é—®é¢˜ç‰¹å¾åˆé›†
    cross_sectional_analyst_prompt = """
    You are a senior radiologist acting as a **pattern recognition specialist** within an AI diagnostic committee.
    Your input consists of three **partial, phase-specific reports** from AI analysts (AP, DP, PVP). Each report represents a 'snapshot' of findings for that specific phase.

    Your task is to review these individual snapshots and create a summary report. For each phase (AP, DP, PVP), describe the overall clinical picture based on the combination of features reported for that phase. **Highlight the key diagnostic contribution of each phase.**
    For example, you might state that the AP phase was crucial for identifying hyperenhancement, while the PVP and DP phases were definitive for confirming washout and an enhancing capsule.

    Your output will be a concise, phase-centric snapshot report for the final Chief Radiologist.
    """
    agent_4b = Agent(instruction=cross_sectional_analyst_prompt, role="Cross-sectional Analyst")

    # --- Execute Agents in Parallel ---
    longitudinal_report = None
    cross_sectional_report = None

    # agent_4aï¼Œagent_4å¹¶è¡Œè¿è¡Œ
    with ThreadPoolExecutor(max_workers=2) as executor:
        cprint("Submitting Agent 4a and 4b tasks to run in parallel...", 'blue')
        
        # Submit each agent's chat method as a separate task
        future_4a = executor.submit(agent_4a.chat, prompt_text=committee_input)
        future_4b = executor.submit(agent_4b.chat, prompt_text=committee_input)
        
        # Retrieve the results as they complete
        # future.result() will wait for the task to finish
        longitudinal_report = future_4a.result()
        cross_sectional_report = future_4b.result()

    cprint("--- Longitudinal Analyst Output ---", 'green')
    # print(longitudinal_report)
    cprint("--- Cross-sectional Analyst Output ---", 'green')
    # print(cross_sectional_report)
    return longitudinal_report, cross_sectional_report


def run_phase_visual(all_image_paths):
    # (æ­¤å‡½æ•°è´Ÿè´£æ‰§è¡Œç¬¬äºŒå’Œç¬¬ä¸‰é˜¶æ®µçš„æ–‡æœ¬åˆ†æ)
    cprint("\n" + "="*60, 'cyan')
    cprint("ğŸ‘€ Executing Visual Adjudicator ğŸ‘€", 'cyan', attrs=['bold'])

    # Agent 5: è§†è§‰ä»²è£å®˜
    cprint("\n[5. Visual Adjudicator] Performing direct comparative analysis of all images...", 'magenta')
    # ä¸ºAgent 5åŠ¨æ€æ„å»ºPrompt
    prompt_sections = []
    for i, feature in enumerate(FEATURE_DEFINITIONS):
        prompt_sections.append(f"""
--- Feature {i+1}: {feature['name']} ---
Answer 0 : "{feature['options'][0]}"
Answer 1 : "{feature['options'][1]}"
""")

    visual_adjudicator_task_prompt = f"""
You are an expert radiologist, the **Visual Adjudicator** for an AI diagnostic committee. Your judgment is final as it is based on direct visual evidence.

**IMAGE CONTEXT:**
You have been provided with a sequence of 9 CT images(3 CT images for each phase). The sequence is ordered by phase:
- **Images 1-3 ** belong to the **Arterial Phase (AP)**.
- **Images 4-6 ** belong to the **Delayed Phase (DP)**.
- **Images 7-9 ** belong to the **Portal Venous Phase (PVP)**.

**CONFIDENCE SCORING RUBRIC (MUST FOLLOW):**
You MUST use the following scale to determine the confidence score. Be very conservative; start with a baseline of 3 and only increase if the evidence is exceptionally strong.
- **5 (Extremely Certain):** The finding is unambiguous, textbook-perfect, and clearly visible on multiple slices or phases. There is no other reasonable interpretation.
- **4 (Very Certain):** The finding is clear and fits the definition, but may not be perfectly "textbook" or has very minor ambiguity.
- **3 (Moderately Certain):** The finding is suggestive but not definitive. Features support this conclusion, but other interpretations are possible. This should be your default for subtle findings.
- **2 (Uncertain):** The evidence is weak, subtle, or could be an imaging artifact. A finding is suspected but cannot be confirmed.
- **1 (Very Uncertain/Guess):** There is virtually no direct evidence.

**YOUR TASK:**
Perform a direct, holistic, and comparative analysis of all images to answer the {len(FEATURE_DEFINITIONS)} key questions. For each feature, you must provide an answer (0 or 1), a confidence score (1-5), and a justification that cites specific image numbers as evidence.
Your final output MUST be a SINGLE, VALID JSON object. 

**FEW-SHOT EXAMPLES:**
```json
{{
    "pattern_1": {{
        "answer": 1,
        "confidence": 5,
        "justification": "For this positive finding, review of the Delayed Phase (DP) sequence (images 4-6) reveals a distinct and smooth hyper-enhancing rim completely encircling the lesion, which was not visible in the Arterial Phase."
    }},
    "pattern_2": {{
        "answer": 0,
        "confidence": 4,
        "justification": "For this negative finding, review of the Arterial Phase (AP) sequence (images 1-3) shows homogeneous enhancement in the liver parenchyma surrounding the lesion, with no evidence of the characteristic wedge-shaped or halo-like hyperenhancement."
    }}
}}

**QUESTIONS TO ANSWER:**
{''.join(prompt_sections)}
"""

    visual_adjudicator_instruction = "You are an expert radiologist, the **Visual Adjudicator** for an AI diagnostic committee. Follow all instructions in the user prompt precisely."
    agent_5 = Agent(instruction=visual_adjudicator_instruction, role="Visual Adjudicator")
    # è§†è§‰ä»²è£å®˜çš„promptæ¯”è¾ƒç®€å•ï¼Œå› ä¸ºå®ƒä¸»è¦ä¾èµ–äºå›¾åƒè¾“å…¥
    visual_adjudicator_report = agent_5.chat(prompt_text=visual_adjudicator_task_prompt, image_paths=all_image_paths)
    cprint("--- Visual Adjudicator (5) Output ---", 'green')
    # print(visual_adjudicator_report)

    return visual_adjudicator_report


def run_phase_3(longitudinal_report, cross_sectional_report, visual_adjudicator_report):
    """
    æ‰§è¡Œç¬¬ä¸‰é˜¶æ®µï¼šè¿è¡Œé¦–å¸­æ•´åˆå®˜ï¼Œç»¼åˆæ‰€æœ‰åˆ†ææŠ¥å‘Šã€‚
    """
    cprint("ğŸ‘¨â€âš•ï¸ [Phase 3: Final Decision Making] ğŸ‘¨â€âš•ï¸", 'cyan', attrs=['bold'])
    
    # å‡†å¤‡ç»™é¦–å¸­æ•´åˆå®˜çš„è¾“å…¥ï¼Œç°åœ¨åŒ…å«ä¸‰ä»½æŠ¥å‘Š
    synthesis_input = f"""
    [Feature Evolution Report from Cross-Phase Analyst]:
    {longitudinal_report}
    [Diagnostic Snapshot Report from Pattern Recognition Analyst]:
    {cross_sectional_report}
    [Visual Adjudicator Report from Direct Image Analysis]:
    {visual_adjudicator_report}
    """
    cprint("\n[6. Chief Synthesizer] Synthesizing all three expert reports...", 'magenta')

    # Agent 5: é¦–å¸­æ•´åˆå®˜
    chief_synthesizer_prompt = f"""
You are the **Chief Radiologist** presiding over an AI diagnostic committee. Your task is to provide the final, global conclusion by synthesizing three expert reports.

**Your Inputs:**
1.  A **Feature Evolution Report** from the Cross-Phase Analyst (summarizing text-based findings over time).
2.  A **Diagnostic Snapshot Report** from the Pattern Recognition Analyst (summarizing text-based findings by phase).
3.  A **Visual Adjudicator Report** (based on direct analysis of all images, with confidence scores).

**Your Reasoning Process:**
Your primary job is to synthesize three expert perspectives to form a final, reasoned conclusion. Based on testing, the text-based analysis (reports 1 & 2) has been found to be more consistently reliable. Therefore, you must follow this **Conflict Resolution Protocol**:

1.  **Establish Primary Finding from Text:** First, for each of the 9 features, establish a "primary finding" by synthesizing the **Feature Evolution Report** and the **Diagnostic Snapshot Report** (reports 1 & 2). This text-based conclusion is your baseline.

2.  **Use Visual Report for Verification:** Next, use the **Visual Adjudicator Report** (report 3) to either **confirm** or **challenge** this primary finding.

3.  **Handle Agreement and Conflict:**
    * **If they AGREE:** The finding is confirmed with high confidence. Your justification should reflect this consensus.
    * **If they CONFLICT:** This indicates a significant discrepancy. You must handle it with caution:
        * **Default Stance:** Your default decision should be to **trust the primary finding from the text-based analysis (reports 1 & 2)**.
        * **Condition for Override:** You may only override the text-based finding and adopt the Visual Adjudicator's conclusion if, and only if, the Visual Adjudicator's report meets **BOTH** of these strict criteria:
            a) Its confidence score is the **maximum possible (e.g., 5/5)**.
            b) Its justification provides **exceptionally clear, unambiguous, and compelling evidence**, citing specific image numbers.
        * If the override condition is not met, you stick with the text-based finding.

4.  **Justify Your Final Decision:** In your final `justification` for each feature, you must be transparent about the process:
    * If the reports agreed, state the consensus. (e.g., *"Confirmed by both text-based analysis and direct visual review."*)
    * If there was a conflict that you resolved, explain your decision. (e.g., *"While the Visual Adjudicator reported a possible finding, the text-based analysis from all initial phase-analysts was consistently negative. Defaulting to the more reliable text-based consensus."* or *"Overriding the text-based analysis due to a definitive, max-confidence (5/5) visual findin

Your final output MUST be a single block of text that strictly follows the three-part structure outlined below. It is CRITICAL that you include the exact headings for each section, including the numbering.
**Required Output Format:**
1.  **Core Conclusion:** 
    A concise paragraph summarizing the overall clinical findings and conclusion.

2.  **Main Evidence:**
    A bulleted points detailing the key evidence from both the longitudinal, cross-sectional and visual reports that support your core conclusion.

3.  **Structured Summary:**
    This section MUST be a single, valid JSON object and nothing else. Do not add any introductory text, markdown tags like ```json, or any text after the JSON object.
    The JSON object must summarize the final answer for each of the 9 features. It must have keys from "pattern_1" to "pattern_9", corresponding to the features in this order:
    1. Enhancing Capsule
    2. Peritumoral Perfusion Alteration
    3. Peritumoral Hypodense Halo
    4. Corona Enhancement
    5. Custom TTPVI Feature
    6. Fade Enhancement Pattern
    7. Nodule-in-Nodule Architecture
    8. Peripheral Washout
    9. Delayed Central Enhancement

    For each pattern, the value must be an object with two keys:
    - "answer": The final binary conclusion (0 for first description, 1 for second description).
    - "justification": A brief, concise summary of the reasoning.

**Before generating the final output, double-check that the JSON syntax is perfect, especially for **Structured Summary:**, ensuring that a comma (`,`) separates every pattern object from the next.**

Example of the required structure for the JSON part ONLY:
```json
{{
    "pattern_1": {{
        "answer": 1,
        "justification": "Visible as a distinct, enhancing rim in the PVP/DP, which was not clearly defined in the AP."
    }},
    "pattern_2": {{
        "answer": 0,
        "justification": "No transient, wedge-shaped hyperenhancement was observed; any minor surrounding brightness in the AP persisted into the PVP."
    }},
    "pattern_7": {{
        "answer": 0,
        "justification": "The lesion's internal enhancement was reported as homogeneous across all three phases, lacking a distinct inner nodule."
    }}
}}
"""

    agent_6 = Agent(instruction=chief_synthesizer_prompt, role="Chief Synthesizer")
    final_hybrid_output = agent_6.chat(prompt_text=synthesis_input)
    # print(f"agent_6 output: \n{final_hybrid_output}")


    # ã€ã€æ–°ã€‘ã€‘å¢åŠ è§£æé€»è¾‘ï¼Œåˆ†ç¦»æ–‡æœ¬æŠ¥å‘Šå’ŒJSONå¯¹è±¡
    prose_report = ""

    try:
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥åˆ†å‰²ï¼Œæ›´å¼ºå¤§ã€æ›´å®½å®¹
        pattern = re.compile(r'3\.\s*\**Structured\s+Summary\**:', re.IGNORECASE)
        parts = pattern.split(final_hybrid_output, 1)

        if len(parts) == 2:
            prose_report = parts[0].strip()
            json_text = parts[1].strip() # è¿™æ˜¯å¯èƒ½åŒ…å«æ‚è´¨çš„JSONæ–‡æœ¬
            
            # ã€ã€ã€æ ¸å¿ƒä¿®æ”¹ï¼šæ™ºèƒ½æå–ã€‘ã€‘ã€‘
            # ä»å¯èƒ½æ··æ‚çš„æ–‡æœ¬ä¸­ï¼Œç²¾ç¡®æ‰¾åˆ°ç¬¬ä¸€ä¸ª '{' å’Œæœ€åä¸€ä¸ª '}'
            start_index = json_text.find('{')
            end_index = json_text.rfind('}')

            if start_index != -1 and end_index != -1 and end_index > start_index:
                # ç²¾ç¡®æå–ä» '{' åˆ° '}' çš„æ‰€æœ‰å†…å®¹
                actual_json_text = json_text[start_index : end_index + 1]
                
                # ç°åœ¨å¯¹è¿™ä¸ªçº¯å‡€çš„å­—ç¬¦ä¸²è¿›è¡Œè§£æ
                structured_summary = json.loads(actual_json_text)
                cprint("âœ… Successfully extracted and parsed JSON.", 'green')
            else:
                # å¦‚æœè¿ '{' å’Œ '}' éƒ½æ‰¾ä¸åˆ°
                cprint("Error: Could not find a valid JSON object within the summary section.", "red")
                structured_summary = {"error": "JSON object start '{' or end '}' not found.", "raw_json_text": json_text}
        else:
            # å¦‚æœæ­£åˆ™è¡¨è¾¾å¼æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„åˆ†å‰²ç‚¹
            prose_report = final_hybrid_output
            structured_summary = {"error": "Structured Summary section heading not found in the output.", "raw_response": final_hybrid_output}

    except Exception as e:
        cprint(f"An unexpected error occurred during parsing: {e}", "red")
        prose_report = final_hybrid_output
        structured_summary = {"error": f"An unexpected error occurred. Details: {e}", "raw_response": final_hybrid_output}

    # --- æ‰“å°æœ€ç»ˆç»“æœ ---
    print("\n" + "="*20 + " åˆ†å‰²ç»“æœ " + "="*20)

    print("\n--- ç¬¬ä¸€éƒ¨åˆ†ï¼šæ–‡æœ¬æŠ¥å‘Š (Prose Report) ---")
    print(prose_report)

    print("\n--- ç¬¬äºŒéƒ¨åˆ†ï¼šç»“æ„åŒ–æ€»ç»“ (Structured Summary JSON) ---")
    # ä½¿ç”¨json.dumpsç¾åŒ–æ‰“å°è¾“å‡ºï¼Œæ–¹ä¾¿æŸ¥çœ‹
    print(json.dumps(structured_summary, indent=4, ensure_ascii=False))

    # è¿”å›ä¸¤ä¸ªéƒ¨åˆ†ï¼šæ–‡æœ¬æŠ¥å‘Šå’Œç»“æ„åŒ–å­—å…¸
    return prose_report, structured_summary

# --- 5. ä¸»æ‰§è¡Œé€»è¾‘ (Main Execution Logic) ---

def main():
    # (è¿™æ˜¯ä¸»å‡½æ•°ï¼Œè´Ÿè´£ç¼–æ’æ•´ä¸ªæµç¨‹)
    all_patient_results = {}

    try:
        patient_ids = [d for d in os.listdir(BASE_DATA_PATH) if os.path.isdir(os.path.join(BASE_DATA_PATH, d))]
        patient_ids.sort()
        if not patient_ids:
            cprint(f"Error: No patient folders found in '{BASE_DATA_PATH}'.", 'red')
            return
        cprint(f"Found {len(patient_ids)} patient folder(s). Starting processing...", 'cyan', attrs=['bold'])
    except FileNotFoundError:
        cprint(f"Error: The directory '{BASE_DATA_PATH}' was not found. Please check the path.", 'red')
        return

    for patient_id in tqdm(patient_ids, desc="Processed Patients"):
        cprint(f"\n{'='*20} Processing Patient: {patient_id} {'='*20}", 'yellow')
        patient_folder = os.path.join(BASE_DATA_PATH, patient_id)
        
        # ä¸ºæ¯ä¸ªæ—¶æœŸæ”¶é›†å›¾åƒè·¯å¾„
        image_paths_ap = sorted([os.path.join(patient_folder, 'AP', f) for f in os.listdir(os.path.join(patient_folder, 'AP')) if f.endswith('.png')])
        image_paths_dp = sorted([os.path.join(patient_folder, 'DP', f) for f in os.listdir(os.path.join(patient_folder, 'DP')) if f.endswith('.png')])
        image_paths_pvp = sorted([os.path.join(patient_folder, 'PVP', f) for f in os.listdir(os.path.join(patient_folder, 'PVP')) if f.endswith('.png')])
        
        if not all([image_paths_ap, image_paths_dp, image_paths_pvp]):
            cprint(f"Warning: Patient {patient_id} is missing images in one or more phase folders. Skipping.", 'red')
            continue


        # 2. è°ƒç”¨AIæ¥å¯»æ‰¾æ ¸å¿ƒåˆ‡ç‰‡
        core_slice_num = find_core_slice(image_paths_pvp)

        if core_slice_num is None:
            cprint(f"Could not determine a core slice for patient {patient_id}. Skipping.", 'red')
            all_patient_results[patient_id] = {"error": "Core slice selection failed."}
            continue
            
        # 3. é€‰å‡ºvisual agentæ¯ä¸ªæ—¶æœŸåº”è¯¥çœ‹çš„3å¼ å›¾
        selected_paths_ap, selected_paths_dp, selected_paths_pvp = select_final_slices(
            core_slice_num, image_paths_ap, image_paths_dp, image_paths_pvp
        )

        # å¦‚æœé€‰æ‹©å¤±è´¥ï¼ˆä¾‹å¦‚æ ¸å¿ƒåˆ‡ç‰‡æœªåœ¨åˆ—è¡¨ä¸­æ‰¾åˆ°ï¼‰ï¼Œåˆ™è·³è¿‡
        if selected_paths_ap is None:
            all_patient_results[patient_id] = {"error": f"Core slice {core_slice_num} could not be located in the image lists."}
            continue


        # æ‰§è¡Œç¬¬ä¸€é˜¶æ®µï¼Œæ¯æ—¶æœŸ10å¼ å›¾
        phase1_reports = run_phase_1(image_paths_ap, image_paths_dp, image_paths_pvp)
        # print(f"phase1 reports: {phase1_reports}")
        
        # 2. æ‰§è¡Œç¬¬äºŒé˜¶æ®µ
        all_images = selected_paths_ap + selected_paths_dp + selected_paths_pvp
        long_report, cross_report = run_phase_2(phase1_reports)
        # æ¯æ—¶æœŸ3å¼ å›¾
        visual_report = run_phase_visual(all_images)
        print(f"-------------long_report:------------- \n{long_report}\n")
        print(f"-------------cross_report:------------- \n{cross_report}\n")
        print(f"-------------visual_report:------------- \n{visual_report}\n")
        
        # 3. æ‰§è¡Œç¬¬ä¸‰é˜¶æ®µ
        prose_report, structured_summary = run_phase_3(long_report, cross_report, visual_report)
        
        # æ”¶é›†ç»“æœ
        all_patient_results[patient_id] = structured_summary


    # å°†æ‰€æœ‰ç—…äººçš„ç»“æœä¿å­˜åˆ°ä¸€ä¸ªJSONæ–‡ä»¶ä¸­
    output_filename = "multi_agent_external_results.json"
    with open(output_filename, 'w', encoding='utf-8') as f:
        json.dump(all_patient_results, f, ensure_ascii=False, indent=4)
    
    cprint(f"\n\nğŸ‰ All processing complete. All reports have been saved to '{output_filename}'.", 'cyan', attrs=['bold'])


if __name__ == '__main__':
    main()
