import os
import json
import base64
import requests
from tqdm import tqdm
from termcolor import cprint
import google.auth
import google.auth.transport.requests
from google.oauth2 import service_account
import re
import json
from concurrent.futures import ThreadPoolExecutor
from typing import List, Tuple


# --- 1. é…ç½®åŒº (Configuration Section) ---
# è¯·åœ¨æ­¤å¤„ä¿®æ”¹æ‚¨çš„ä¸ªäººé…ç½®

# é¡¹ç›®å’Œæ¨¡å‹é…ç½®
VERTEX_AI_CONFIG = {
    "project_id": "gen-lang-client-0514315738",
    "location": "us-central1",
    # ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘è¯·åŠ¡å¿…ä¿®æ”¹ä¸ºæ‚¨çš„æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶çš„çœŸå®è·¯å¾„
    "credentials_path": "/home/yxcui/FM-Bridge/testing_file/gen-lang-client-0514315738-faeaf04b384e.json",
    "model_name": "gemini-2.5-pro"  # gemini-2.5-flash
}

# ä»£ç†é…ç½®
PROXY_CONFIG = {
    # å¦‚æœæ‚¨ä¸éœ€è¦ä»£ç†ï¼Œè¯·å°†æ­¤è¡Œè®¾ç½®ä¸º None, ä¾‹å¦‚ï¼š'https': None
    'https': 'socks5://hkumedai:bestpaper@66.42.72.8:54321' 
}

# ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘è¯·ä¿®æ”¹ä¸ºæ‚¨çš„æ•°æ®é›†æ ¹ç›®å½•
BASE_DATA_PATH = "/home/yxcui/FM-Bridge/testing_file/test_dataset/cropped_30_slices_image"


# è§„åˆ™ï¼šå®šä¹‰æ¯ä¸ªç‰¹å¾æœ€ç»ˆè¯Šæ–­æ‰€å¿…éœ€çš„æœŸç›¸
FEATURE_PHASE_REQUIREMENTS = {
    "Enhancing Capsule": ["AP", "PVP", "DP"], # 44
    "Peritumoral Perfusion Alteration": ["AP", "PVP"], # 53
    "Peritumoral Hypodense Halo": ["PVP", "DP"], # 59
    "Corona Enhancement": ["AP", "PVP", "DP"], # 60
    "Custom TTPVI Feature": ["AP", "PVP", "DP"], # 62 
    "Fade Enhancement Pattern": ["AP", "PVP", "DP"], # 65
    "Nodule-in-Nodule Architecture": ["AP", "PVP", "DP"], # 66
    "Peripheral Washout": ["AP", "PVP", "DP"], # 68
    "Delayed Central Enhancement": ["AP", "DP"] # 70
}

# --- ä¸´åºŠé—®é¢˜å®šä¹‰ (Clinical Question Definitions) ---
# å°†é—®é¢˜åˆ—è¡¨å®šä¹‰ä¸ºå…¨å±€å¸¸é‡ï¼Œä¾›æ‰€æœ‰Agentè®¿é—®
FEATURE_DEFINITIONS = [
    {
        "name": "Enhancing Capsule", # 44
        "options": [
            'A distinct, hyper-enhancing rim is NOT identified in the PVP/DP, or any visible rim does not show clear enhancement compared to the AP.',
            'By comparing phases, a smooth rim is identified that enhances to become distinctly hyper-enhancing in the PVP or DP.'
        ]
    },
    {
        "name": "Peritumoral Perfusion Alteration", # 53
        "options": [
            'No clear perfusion anomalies are seen in the AP, or any observed hyperenhancement around the lesion persists into the PVP.',
            'A transient perfusion anomaly is confirmed: wedge-shaped or halo-like hyperenhancement is visible around the lesion in the AP and resolves (disappears) in the PVP.'
        ]
    },
    {
        "name": "Peritumoral Hypodense Halo", # 59
        "options": [
            'In the PVP or DP, the interface between the lesion and the surrounding liver parenchyma is direct, without a distinct, dark, intervening ring.',
            'In the PVP or DP, a distinct, dark (hypodense), well-defined ring is visible immediately surrounding the exterior of the lesion. This "halo" is darker than both the lesion\'s periphery and the adjacent liver tissue.'
        ]
    },
    {
        "name": "Corona Enhancement", # 60
        "options": [
            'No radiating vascular pattern is seen at the tumor periphery in any phase.',
            'A dynamic "corona enhancement" is identified: a radiating vascular pattern appears at the tumor periphery in the late AP or PVP and fades in later phases.'
        ]
    },
    {
        "name": "Custom TTPVI Feature", # 62
        "options": [
            'The combined pattern is ABSENT. This condition is met if the AP analysis fails to show distinct intratumoral arteries, OR if the PVP/DP analysis reveals the presence of a peritumoral hypodense halo.',
            'The combined pattern is PRESENT. This requires a two-step confirmation: 1) The AP analysis must show distinct, dot-like or linear hyper-enhancing structures (intratumoral arteries) inside the lesion, AND 2) The PVP/DP analysis must confirm the absence of a peritumoral hypodense halo.'
        ]
    },
    {
        "name": "Fade Enhancement Pattern", # 65
        "options": [
            'Comparing phases, the lesion becomes hypodense relative to surrounding liver in the PVP or DP, demonstrating a "washout" pattern.',
            'Comparing phases, the lesion enhancement persists, remaining iso- or hyper-enhancing relative to surrounding liver in the PVP or DP, demonstrating a "fade" (non-washout) pattern.'
        ]
    },
    {
        "name": "Nodule-in-Nodule Architecture", # 66
        "options": [
            'Across all phases, the lesion\'s internal enhancement is either homogeneous or chaotically heterogeneous, lacking a clear, stable hierarchical structure.',
            'A "nodule-in-nodule" architecture is confirmed across phases: a smaller nodule shows more intense AP enhancement than the larger parent lesion, and this distinction often persists in later phases.'
        ]
    },
    {
        "name": "Peripheral Washout", # 68
        "options": [
            'After initial AP enhancement, the lesion either does not show washout or shows a non-peripheral (diffuse) washout pattern in the PVP/DP.',
            'After initial AP enhancement, the lesion shows a distinct "peripheral washout" pattern, with only its rim becoming hypoenhancing in the PVP/DP.'
        ]
    },
    {
        "name": "Delayed Central Enhancement", # 70
        "options": [
            'Comparing phases, the central part of the lesion does not show progressive enhancement (e.g., it washes out or remains persistently non-enhancing).',
            'Comparing phases, the central part of the lesion shows progressive, sustained enhancement, becoming brighter in the delayed phase than it was in the AP.'
        ]
    }
]


# --- 2. è¾…åŠ©å‡½æ•° (Helper Functions) ---

def encode_image_to_base64(image_path):
    # (æ­¤å‡½æ•°ç”¨äºå°†å›¾ç‰‡ç¼–ç ä¸ºBase64)
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except FileNotFoundError:
        cprint(f"Warning: Image file not found at {image_path}. Skipping.", 'red')
        return None

# --- 3. æ™ºèƒ½ä½“æ ¸å¿ƒç±» (Agent Core Class) ---

class Agent:
    def __init__(self, instruction, role):
        # (æ­¤å¤„çš„ Agent ç±»ä¸æˆ‘ä»¬ä¹‹å‰ç‰ˆæœ¬ç›¸åŒï¼Œä½¿ç”¨ Gemini API)
        self.system_instruction = {"parts": [{"text": instruction}]}
        self.role = role
        self.config = VERTEX_AI_CONFIG
        self.proxies = PROXY_CONFIG if PROXY_CONFIG.get('https') else None

    def _get_access_token(self):
        # (æ­¤å‡½æ•°ç”¨äºé€šè¿‡æœåŠ¡è´¦å·è·å–è®¿é—®ä»¤ç‰Œ)
        try:
            credentials = service_account.Credentials.from_service_account_file(
                self.config['credentials_path'],
                scopes=['https://www.googleapis.com/auth/cloud-platform']
            )
            auth_req = google.auth.transport.requests.Request()
            credentials.refresh(auth_req)
            return credentials.token
        except Exception as e:
            cprint(f"Error authenticating from service account file: {e}", 'red')
            raise

    def chat(self, prompt_text, image_paths=None):
        # (æ­¤å‡½æ•°æ˜¯ Agent çš„æ ¸å¿ƒï¼Œè´Ÿè´£è°ƒç”¨ Gemini API)
        if image_paths is None:
            image_paths = []
            
        try:
            access_token = self._get_access_token()
        except Exception:
            return "Could not authenticate. Please check your service account credentials path and permissions."

        url = f"https://{self.config['location']}-aiplatform.googleapis.com/v1/projects/{self.config['project_id']}/locations/{self.config['location']}/publishers/google/models/{self.config['model_name']}:streamGenerateContent"
        headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}

        parts = [{"text": prompt_text}]
        valid_image_count = 0
        for image_path in image_paths:
            base64_image = encode_image_to_base64(image_path)
            if base64_image:
                parts.append({"inline_data": {"mime_type": "image/png", "data": base64_image}})
                valid_image_count += 1
        
        payload = {
            "system_instruction": self.system_instruction,
            "contents": [{"role": "user", "parts": parts}],
            "generationConfig": {"temperature": 0.0, "maxOutputTokens": 8192}
        }
        
        cprint(f" Agent '{self.role}' is sending request to {self.config['model_name']} with {valid_image_count} image(s)...", 'blue')

        try:
            response = requests.post(url, headers=headers, json=payload, proxies=self.proxies)
            if response.status_code != 200:
                cprint(f"API Error: {response.status_code}\nResponse: {response.text}", 'red')
                return f"API Error: Received status code {response.status_code}"
            
            response.raise_for_status()
            
            full_text_response = "".join(
                item['candidates'][0]['content']['parts'][0]['text']
                for item in response.json()
                if 'candidates' in item and 'content' in item['candidates'][0] and 'parts' in item['candidates'][0]['content']
            )
            
            if not full_text_response:
                cprint(f"Error: Response contained no text. Full Response: {response.json()}", 'red')
                return "Error: Model returned an empty response."

            return full_text_response

        except requests.exceptions.RequestException as e:
            cprint(f"Network error calling Vertex AI API: {e}", 'red')
            return f"Network Error: {e}"
        except Exception as e:
            cprint(f"An unknown error occurred while processing Vertex AI response: {e}", 'red')
            return f"Unknown Error: {e}"




# --- 4. å·¥ä½œæµå„é˜¶æ®µå‡½æ•° (Workflow Phase Functions) ---

def select_best_five_slices(image_paths_pvp):
    """
    ä½¿ç”¨ä¸¤é˜¶æ®µAIæµç¨‹ï¼Œä»ä¸€ä¸ªæœŸç›¸çš„å›¾ç‰‡åˆ—è¡¨ä¸­æ™ºèƒ½é€‰å‡ºä¸€ä¸ªåŒ…å«5å¼ å›¾ç‰‡çš„â€œä»£è¡¨æ€§ç»„åˆâ€ã€‚

    :param image_paths_pvp: PVPæœŸç›¸çš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨ã€‚
    :return: é€‰å‡ºçš„5å¼ å›¾ç‰‡çš„è·¯å¾„åˆ—è¡¨ (list)ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› Noneã€‚
    """
    cprint("\n--- [å¯åŠ¨â€œä»£è¡¨æ€§åˆ‡ç‰‡ç»„åˆâ€æ™ºèƒ½ç­›é€‰å­æµç¨‹] ---", 'blue', attrs=['bold'])

    # --- å®šä¹‰æœ¬æµç¨‹æ‰€éœ€çš„Agentå’Œé—®é¢˜åˆ—è¡¨ ---

    # 1a. åˆ‡ç‰‡è¯„åˆ†å¤§å¸ˆ (Slice Scoring Master)
    scoring_master_instruction = """
    You are an expert radiologist. Your task is to evaluate a series of CT slices and score each one's **diagnostic utility**.
    You will be provided with multiple images. Your final output must be a single, valid JSON object containing a list of scorecards, one for each slice.
    """
    scoring_master_agent = Agent(instruction=scoring_master_instruction, role="Slice Scoring Master")

    # 1b. ç”„é€‰å†³ç­–å®˜ (Selection Judge)
    selection_judge_instruction = """
    You are the head of radiology. You have been provided with scorecards for multiple CT slices.
    Your task is to select the **5 most representative slices** that, as a group, provide the best overall view of the lesion and are most likely to help answer the clinical questions.
    **Do not simply pick the 5 highest scores.** Aim for a selection that includes the slice with the highest score, but also other slices that might show different aspects of the lesion (e.g., the top edge, the bottom edge, a different internal pattern). Your goal is **coverage and diversity**.
    Your final output must be a JSON object containing a list of the 5 chosen slice numbers.
    """
    selection_judge_agent = Agent(instruction=selection_judge_instruction, role="Selection Judge")

    # 1c. ä»»åŠ¡æ‰€éœ€åˆ†æçš„é—®é¢˜åˆ—è¡¨
    clinical_questions = [
        "1. Enhancing Capsule",
        "2. Peritumoral Perfusion Alteration",
        "3. Peritumoral Hypodense Halo",
        "4. Corona Enhancement",
        "5. Custom TTPVI Feature",
        "6. Fade Enhancement Pattern",
        "7. Nodule-in-Nodule Architecture",
        "8. Peripheral Washout",
        "9. Delayed Central Enhancement"
    ]
    
    # --- é˜¶æ®µä¸€ï¼šæ•´ä½“è¯„åˆ† (â€œæµ·é€‰â€) ---
    cprint("--- [æµ·é€‰é˜¶æ®µ] æ­£åœ¨å°†æ‰€æœ‰PVPåˆ‡ç‰‡ä¸€æ¬¡æ€§å‘é€ç»™è¯„åˆ†å¤§å¸ˆè¿›è¡Œæ¯”è¾ƒå’Œè¯„åˆ†...", 'blue')
    
    slice_numbers = [int(re.search(r'(\d+)\.png$', path).group(1)) for path in image_paths_pvp if re.search(r'(\d+)\.png$', path)]

    scorer_task_prompt = f"""
    You have been provided with {len(image_paths_pvp)} CT images from a PVP sequence, numbered: {slice_numbers}.
    Your task is to **compare all of these images** and generate a scorecard for EACH slice.
    The scores should be relative to this specific set of images.

    For each slice, assign a **"Diagnostic Value Score"** from 1 (not useful) to 10 (critically important).
    A high score should be given to slices that are rich in features and crucial for answering the following clinical questions: {', '.join(clinical_questions)}.
    A slice that clearly shows multiple distinct features should get a very high score.

    Your output MUST be a single, valid JSON object with a root key "scorecards", containing a list of {len(image_paths_pvp)} scorecard objects.
    Each scorecard must have "slice_number", "diagnostic_value_score", and a "reason".
    
    REQUIRED JSON OUTPUT FORMAT:
    {{
        "scorecards": [
            {{
                "slice_number": [slice_num_1],
                "diagnostic_value_score": [Your score 1-10],
                "reason": "Briefly explain why this slice is diagnostically valuable."
            }},
            ...
        ]
    }}
    """
    
    response_text = scoring_master_agent.chat(prompt_text=scorer_task_prompt, image_paths=image_paths_pvp)

    scorecards = []
    try:
        clean_json_text = response_text.strip().replace("```json", "").replace("```", "")
        parsed_response = json.loads(clean_json_text)
        scorecards = parsed_response.get("scorecards", [])
        if scorecards:
            cprint("âœ… è¯„åˆ†å¤§å¸ˆå·²æˆåŠŸè¿”å›è¯„åˆ†æŠ¥å‘Šã€‚", 'green')
            print(f"Scorecards: \n{json.dumps(scorecards, indent=2)}\n")
    except (json.JSONDecodeError, AttributeError):
        cprint(f"Error: Failed to parse JSON from Slice Scoring Master. Response:\n{response_text}", 'red')

    # --- é˜¶æ®µäºŒï¼šæ™ºèƒ½ç”„é€‰ (â€œå†³é€‰â€) ---
    if not scorecards:
        cprint("Error: No valid scorecards were generated. Cannot select slices.", 'red')
        return None

    cprint("\n--- [å†³é€‰é˜¶æ®µ] å¼€å§‹æ ¹æ®è¯„åˆ†æŠ¥å‘Šæ™ºèƒ½é€‰æ‹©5å¼ ä»£è¡¨æ€§åˆ‡ç‰‡...", 'blue')
    
    judge_task_prompt = f"""
    Here are the scorecards for {len(scorecards)} different CT slices. Please select the 5 best and most representative slice numbers.
    Your goal is to choose a diverse set that offers the best overall diagnostic coverage.

    **Scorecards:**
    {json.dumps(scorecards, indent=2)}

    **REQUIRED JSON OUTPUT FORMAT:**
    {{
        "selected_slice_numbers": [a, b, c, d, e]
    }}
    """
    
    response_text = selection_judge_agent.chat(prompt_text=judge_task_prompt)
    
    try:
        clean_json_text = response_text.strip().replace("```json", "").replace("```", "")
        decision = json.loads(clean_json_text)
        selected_numbers = decision["selected_slice_numbers"]
        
        if len(selected_numbers) != 5:
            cprint(f"Warning: Selection Judge returned {len(selected_numbers)} slices instead of 5. Using the result anyway.", 'yellow')

        cprint(f"âœ… AI has selected the 5 most representative slice numbers: {selected_numbers}", 'green', attrs=['bold'])
        
        return selected_numbers

    except (json.JSONDecodeError, KeyError, ValueError) as e:
        cprint(f"Error: Failed to parse JSON from Selection Judge. Error: {e}. Response:\n{response_text}", 'red')
        return None


def select_paths_by_numbers(
    selected_numbers: List[int], 
    image_paths_ap: List[str], 
    image_paths_dp: List[str], 
    image_paths_pvp: List[str]
) -> Tuple[List[str], List[str], List[str]]:
    """
    æ ¹æ®ç»™å®šçš„åˆ‡ç‰‡å·ç åˆ—è¡¨ï¼Œä»ä¸‰ä¸ªæœŸç›¸çš„å®Œæ•´è·¯å¾„åˆ—è¡¨ä¸­ç­›é€‰å‡ºå¯¹åº”çš„æ–‡ä»¶è·¯å¾„ã€‚

    :param selected_numbers: ä¸€ä¸ªåŒ…å«AIé€‰å‡ºçš„åˆ‡ç‰‡å·ç çš„åˆ—è¡¨, e.g., [18, 20, 25, 28, 30]ã€‚
    :param image_paths_ap: APæœŸç›¸çš„å®Œæ•´å›¾ç‰‡è·¯å¾„åˆ—è¡¨ã€‚
    :param image_paths_dp: DPæœŸç›¸çš„å®Œæ•´å›¾ç‰‡è·¯å¾„åˆ—è¡¨ã€‚
    :param image_paths_pvp: PVPæœŸç›¸çš„å®Œæ•´å›¾ç‰‡è·¯å¾„åˆ—è¡¨ã€‚
    :return: ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªç­›é€‰åè·¯å¾„åˆ—è¡¨çš„å…ƒç»„ (selected_ap, selected_dp, selected_pvp)ã€‚
    """
    
    # --- æ­¥éª¤ä¸€ï¼šæ„å»ºâ€œå·ç  -> è·¯å¾„â€çš„å¿«é€ŸæŸ¥æ‰¾å­—å…¸ ---
    # è¿™æ ·åšæ¯”æ¯æ¬¡éƒ½å¾ªç¯æŸ¥æ‰¾è¦é«˜æ•ˆå¾—å¤šã€‚
    
    def create_path_map(paths: List[str]) -> dict:
        """è¾…åŠ©å‡½æ•°ï¼šä»è·¯å¾„åˆ—è¡¨ä¸­åˆ›å»ºå·ç åˆ°è·¯å¾„çš„æ˜ å°„ã€‚"""
        path_map = {}
        for path in paths:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ–‡ä»¶åä¸­å®‰å…¨åœ°æå–æ•°å­—
            match = re.search(r'(\d+)\.png$', path)
            if match:
                slice_num = int(match.group(1))
                path_map[slice_num] = path
        return path_map

    ap_map = create_path_map(image_paths_ap)
    dp_map = create_path_map(image_paths_dp)
    pvp_map = create_path_map(image_paths_pvp)

    # --- æ­¥éª¤äºŒï¼šæ ¹æ®å·ç åˆ—è¡¨æŸ¥æ‰¾å¹¶ç­›é€‰è·¯å¾„ ---
    # ä½¿ç”¨ .get(num) æ–¹æ³•å¯ä»¥å®‰å…¨åœ°å¤„ç†å·ç ä¸å­˜åœ¨çš„æƒ…å†µï¼ˆè¿”å›Noneï¼‰ã€‚
    # if ... is not None ç¡®ä¿äº†åªæœ‰æˆåŠŸæ‰¾åˆ°çš„è·¯å¾„æ‰ä¼šè¢«åŠ å…¥åˆ—è¡¨ã€‚
    
    selected_paths_ap = [ap_map.get(num) for num in selected_numbers if ap_map.get(num) is not None]
    selected_paths_dp = [dp_map.get(num) for num in selected_numbers if dp_map.get(num) is not None]
    selected_paths_pvp = [pvp_map.get(num) for num in selected_numbers if pvp_map.get(num) is not None]
    
    print(f"selected_paths_ap: {selected_paths_ap}")
    print(f"selected_paths_dp: {selected_paths_dp}")
    print(f"selected_paths_pvp: {selected_paths_pvp}")

    return selected_paths_ap, selected_paths_dp, selected_paths_pvp






# åˆ†æ3ä¸ªæ—¶æœŸçš„agent
def run_phase_1(image_paths_ap, image_paths_dp, image_paths_pvp):
    cprint("\n--- [Phase 1: Parallel Feature Extraction with Professional Questions] ---", 'yellow', attrs=['bold'])
    
    # 3. Agentåˆå§‹åŒ–å’Œè°ƒç”¨ 
    # ä¸ºåŠ¨è„‰æœŸ(AP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    ap_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze single CT images from the **Arterial Phase (AP)**.
    Your analysis will be a structured JSON report. It is CRITICAL that your JSON is perfectly formatted and self-contained, as it will be the direct input for a senior AI analyst who will synthesize your report with reports from other phases. Their success depends on the accuracy and clarity of your report.
    You must answer all the specific questions provided below and format your output as a JSON object. 
    Do not add any explanatory text outside of the JSON structure.
    """

    # ä¸ºå»¶è¿ŸæœŸ(DP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    dp_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze single CT images from the **Delayed Phase (DP)**.
    Your analysis will be a structured JSON report. It is CRITICAL that your JSON is perfectly formatted and self-contained, as it will be the direct input for a senior AI analyst who will synthesize your report with reports from other phases. Their success depends on the accuracy and clarity of your report.
    You must answer all the specific questions provided below and format your output as a JSON object. 
    Do not add any explanatory text outside of the JSON structure.
    """

    # ä¸ºé—¨è„‰æœŸ(PVP)åˆ†æå¸ˆåˆ›å»ºæŒ‡ä»¤
    pvp_analyst_instruction = """
    You are a meticulous radiologist. Your task is to analyze single CT images from the **Portal Venous Phase (PVP)**.
    Your analysis will be a structured JSON report. It is CRITICAL that your JSON is perfectly formatted and self-contained, as it will be the direct input for a senior AI analyst who will synthesize your report with reports from other phases. Their success depends on the accuracy and clarity of your report.
    You must answer all the specific questions provided below and format your output as a JSON object. 
    Do not add any explanatory text outside of the JSON structure.
    """

    agent_1 = Agent(instruction=ap_analyst_instruction, role="phase AP Analyst")
    agent_2 = Agent(instruction=dp_analyst_instruction, role="phase DP Analyst")
    agent_3 = Agent(instruction=pvp_analyst_instruction, role="phase PVP Analyst")


    # 2. å‡†å¤‡å­˜å‚¨æ‰€æœ‰ç»“æœçš„å­—å…¸
    all_reports = {"AP": [], "DP": [], "PVP": []}

    # 3. å¤–å±‚å¾ªç¯ï¼šéå†ä¸‰ä¸ªæœŸç›¸
    for phase, paths, agent in [("AP", image_paths_ap, agent_1), 
                                ("DP", image_paths_dp, agent_2), 
                                ("PVP", image_paths_pvp, agent_3)]:
        
        if not paths:
            cprint(f"No slices to process for phase {phase}. Skipping.", 'yellow')
            continue

        cprint(f"\n--- Processing Phase: {phase} ---", 'blue')
        
        # 4. å†…å±‚å¾ªç¯ï¼šéå†å½“å‰æœŸç›¸çš„æ¯ä¸€å¼ åˆ‡ç‰‡
        for image_path in tqdm(paths, desc=f"Analyzing {phase} Slices"):
            
            # ä»æ–‡ä»¶åä¸­æå–åˆ‡ç‰‡å·
            slice_number = "Unknown"
            match = re.search(r'(\d+)\.png$', image_path)
            if match:
                slice_number = match.group(1)

            # 5. ä¸ºå½“å‰æœŸç›¸ç­›é€‰ç›¸å…³é—®é¢˜ (è¿™éƒ¨åˆ†é€»è¾‘ä¸å˜)
            questions_for_this_phase = [
                f for f in FEATURE_DEFINITIONS if phase in FEATURE_PHASE_REQUIREMENTS.get(f['name'], [])
            ]

            if not questions_for_this_phase:
                continue # å¦‚æœå½“å‰æœŸç›¸æ²¡æœ‰éœ€è¦å›ç­”çš„é—®é¢˜ï¼Œåˆ™è·³è¿‡

            # 6. åŠ¨æ€æ„å»ºåªåŒ…å«ç›¸å…³é—®é¢˜å’Œå½“å‰åˆ‡ç‰‡ä¿¡æ¯çš„é«˜çº§Prompt
            prompt_sections = []
            json_findings_template = []
            for i, feature in enumerate(questions_for_this_phase):
                prompt_sections.append(f"""
--- Feature {i+1}: {feature['name']} ---
Option 0 (Feature Absent): "{feature['options'][0]}"
Option 1 (Feature Present): "{feature['options'][1]}"
""")
                json_findings_template.append(
                    f'{{"feature": "{feature["name"]}", "value": <0_or_1>, "evidence": "Provide a brief clinical justification for your choice here."}}'
                )
            
            task_prompt = f"""
You are a meticulous radiologist analyzing a **single CT image** from the **{phase} phase (slice number: {slice_number})**.
For each of the {len(questions_for_this_phase)} features below, analyze the provided image and determine which option (0 or 1) is most accurate.
Format your final output as a SINGLE, VALID JSON object.

{''.join(prompt_sections)}

Your JSON output must follow this exact structure:
{{
  "phase": "{phase}",
  "slice_number": {slice_number},
  "findings": [
    {', '.join(json_findings_template)}
  ]
}}
"""
            # 7. æ¯æ¬¡è°ƒç”¨åªè¾“å…¥1å¼ å›¾ç‰‡
            response_text = agent.chat(prompt_text=task_prompt, image_paths=[image_path])
            
            # 8. è§£æå¹¶å­˜å‚¨è¯¥åˆ‡ç‰‡çš„æŠ¥å‘Š
            try:
                clean_json_text = response_text.strip().replace("```json", "").replace("```", "")
                report_for_slice = json.loads(clean_json_text)
                all_reports[phase].append(report_for_slice)
                cprint(f"  Successfully processed slice {slice_number} for phase {phase}.", 'green')
            except (json.JSONDecodeError, AttributeError):
                cprint(f"  Error: Failed to parse JSON for slice {slice_number} (Phase {phase}). Response:\n{response_text}", 'red')
                all_reports[phase].append({"error": "Failed to parse", "slice": slice_number, "raw_response": response_text})

    print(f"phase_1 output: {all_reports}")
    return all_reports


# 
def run_phase_2(phase1_reports, selected_slice_numbers):
    """
    ç¬¬äºŒé˜¶æ®µ (å·¦åˆ†æ”¯): è·¨æœŸç›¸æ–‡æœ¬æ•´åˆã€‚
    æŒ‰åˆ‡ç‰‡å·ï¼Œä¸ºæ¯ä¸ªåˆ‡ç‰‡æ•´åˆå…¶åœ¨AP, DP, PVPä¸‰ä¸ªæœŸç›¸çš„åˆçº§æŠ¥å‘Šã€‚
    è¿™5ä¸ªç‹¬ç«‹çš„æ•´åˆä»»åŠ¡å°†å¹¶è¡Œæ‰§è¡Œã€‚
    """
    cprint("\n--- [Phase 2: Per-Slice Text Synthesis (Parallel)] ---", 'yellow', attrs=['bold'])

    # 1. åˆå§‹åŒ– Agent
    # è¿™ä¸ªAgentçš„è§’è‰²æ˜¯æ•´åˆå•ä¸€å±‚é¢çš„ä¸‰ä»½æŠ¥å‘Š
    text_synthesis_instruction = """
    You are a senior radiologist acting as a **cross-phase synthesis specialist**.
    Your task is to synthesize three phase-specific reports (AP, DP, PVP) that all describe the **same single anatomical slice**.
    Your goal is to create one cohesive, text-based analysis report that summarizes the lesion's complete dynamic behavior on this specific slice.
    Highlight the evolution of features, any inconsistencies, and the overall pattern observed.
    Your output should be a concise, analytical paragraph.
    """
    agent_4 = Agent(instruction=text_synthesis_instruction, role="Text Synthesis Analyst")
    
    # 2. å‡†å¤‡å¹¶è¡Œæ‰§è¡Œ
    synthesized_reports_by_slice = {}
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_slice = {}
        
        # 3. å¤–å±‚å¾ªç¯ï¼šéå†5ä¸ªè¢«é€‰ä¸­çš„åˆ‡ç‰‡å·
        for slice_num in selected_slice_numbers:
            cprint(f"Submitting text synthesis task for slice #{slice_num}...", 'magenta')
            
            # 4. ä¸ºå½“å‰åˆ‡ç‰‡å·ï¼Œä»phase1_reportsä¸­æ”¶é›†ä¸‰ä»½å¯¹åº”çš„æŠ¥å‘Š
            try:
                # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼é«˜æ•ˆåœ°æ‰¾åˆ°å¯¹åº”åˆ‡ç‰‡çš„æŠ¥å‘Š
                report_ap = next(item for item in phase1_reports['AP'] if item.get('slice_number') == slice_num)
                report_dp = next(item for item in phase1_reports['DP'] if item.get('slice_number') == slice_num)
                report_pvp = next(item for item in phase1_reports['PVP'] if item.get('slice_number') == slice_num)
            except StopIteration:
                cprint(f"Warning: Missing one or more phase reports for slice #{slice_num}. Skipping.", 'yellow')
                continue

            # 5. æ„å»ºä¸“å±çš„ã€å…³äºå½“å‰åˆ‡ç‰‡çš„Prompt
            task_prompt = f"""
            Please synthesize the following three reports for **slice number {slice_num}** into a single, comprehensive text analysis.

            [Report from phase AP for slice {slice_num}]:
            {json.dumps(report_ap.get('findings', []), indent=2, ensure_ascii=False)}

            [Report from phase DP for slice {slice_num}]:
            {json.dumps(report_dp.get('findings', []), indent=2, ensure_ascii=False)}

            [Report from phase PVP for slice {slice_num}]:
            {json.dumps(report_pvp.get('findings', []), indent=2, ensure_ascii=False)}

            Your output should be a single, analytical paragraph summarizing your findings for this slice.
            """
            
            # 6. æäº¤å¹¶è¡Œä»»åŠ¡
            future = executor.submit(agent_4.chat, prompt_text=task_prompt)
            future_to_slice[future] = slice_num

        # 7. æ”¶é›†å¹¶è¡Œä»»åŠ¡çš„ç»“æœ
        cprint("Waiting for per-slice text synthesis tasks to complete...", 'blue')
        for future in tqdm(as_completed(future_to_slice), total=len(future_to_slice), desc="Synthesizing Slices"):
            slice_num = future_to_slice[future]
            try:
                result_text = future.result()
                synthesized_reports_by_slice[slice_num] = result_text
                synthesized_reports_by_slice = dict(sorted(synthesized_reports_by_slice.items()))
            except Exception as exc:
                cprint(f"\nAn exception occurred while synthesizing slice #{slice_num}: {exc}", 'red')
                synthesized_reports_by_slice[slice_num] = {"error": str(exc)}

    cprint("\n--- Text Synthesis Reports (by Slice) ---", 'green')
    print(json.dumps(synthesized_reports_by_slice, indent=2, ensure_ascii=False))

    return synthesized_reports_by_slice


# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
def _analyze_single_slice_level_visual(agent, slice_num, focus_image_paths):
    """
    ã€ä¿®æ­£ç‰ˆã€‘è¾…åŠ©å‡½æ•°ï¼šå¯¹å•ä¸€è§£å‰–å±‚é¢å¯¹åº”çš„3å¼ æœŸç›¸å›¾ç‰‡è¿›è¡Œè¯¦ç»†è§†è§‰åˆ†æã€‚
    """
    
    # åŠ¨æ€æ„å»ºé—®é¢˜åˆ—è¡¨ (è¿™éƒ¨åˆ†é€»è¾‘ä¸å˜)
    prompt_sections = []
    for i, feature in enumerate(FEATURE_DEFINITIONS):
        prompt_sections.append(f"""
--- Feature {i+1}: {feature['name']} ---
Answer 0 (Absent): "{feature['options'][0]}"
Answer 1 (Present): "{feature['options'][1]}"
""")

    # ã€ä¿®æ­£ç‰ˆã€‘Promptç°åœ¨åªå…³æ³¨è¿™3å¼ æ ¸å¿ƒå›¾ç‰‡
    fine_grained_visual_prompt = f"""
You are an expert radiologist, the **Visual Adjudicator** for an AI committee. Your task is to perform a fine-grained analysis of a **single anatomical slice level** across its three contrast phases.

**IMAGE CONTEXT:**
You have been provided with **3 CT images** corresponding to slice number **{slice_num}**:
- Image 1: Arterial Phase (AP)
- Image 2: Delayed Phase (DP)
- Image 3: Portal Venous Phase (PVP)

**YOUR TASK:**
Synthesize the visual information for slice **{slice_num}**. For each of the {len(FEATURE_DEFINITIONS)} features, choose the most accurate description (0 or 1), provide a confidence score (1-5), and a justification. Your justification MUST be based on direct, multi-phase visual evidence from the provided images for this slice level.

**FEW-SHOT EXAMPLES:**
Here are examples of the high-quality, evidence-based reasoning required:
{{
    "pattern_1": {{
        "answer": 1,
        "confidence": 5,
        "justification": "On slice #{slice_num}, review of the Delayed Phase (DP) sequence (images 6-10) reveals a distinct and smooth hyper-enhancing rim completely encircling the lesion, which was not visible in the Arterial Phase. This feature is consistent with the adjacent slices."
    }},
    "pattern_2": {{
        "answer": 0,
        "confidence": 4,
        "justification": "On slice #{slice_num}, review of the Arterial Phase (AP) sequence (images 1-5) shows homogeneous enhancement in the liver parenchyma surrounding the lesion, with no evidence of the characteristic wedge-shaped or halo-like hyperenhancement, and this observation is consistent with the adjacent slices."
    }}
}}

**QUESTIONS TO ANSWER for Slice #{slice_num}:**
{''.join(prompt_sections)}

**REQUIRED OUTPUT FORMAT:**
Your output MUST be a SINGLE, VALID JSON object for this slice. It should contain a list of {len(FEATURE_DEFINITIONS)} findings.
Example: {{ "slice_findings": [...] }}
"""
    
    # ã€ã€æ ¸å¿ƒä¿®æ­£ã€‘ã€‘
    # å·¥äººå‡½æ•°ç°åœ¨åªå°†ã€3å¼ ç„¦ç‚¹å›¾ç‰‡ã€‘çš„è·¯å¾„ä¼ é€’ç»™API
    response_text = agent.chat(prompt_text=fine_grained_visual_prompt, image_paths=focus_image_paths)
    
    try:
        clean_json_text = response_text.strip().replace("```json", "").replace("```", "")
        return json.loads(clean_json_text)
    except (json.JSONDecodeError, AttributeError):
        return {"error": "Failed to parse JSON", "raw_response": response_text, "slice_number": slice_num}
    

def run_phase_visual(selected_ap, selected_dp, selected_pvp, selected_numbers):
    cprint("\n--- [Visual Adjudicator: Fine-grained, Per-Slice Analysis (Parallel)] ---", 'yellow', attrs=['bold'])

    visual_adjudicator_instruction = "You are an expert radiologist, the Visual Adjudicator for an AI committee. Provide a detailed report for one specific slice at a time based on its 3-phase images. Follow all instructions in the user prompt precisely."
    agent_5 = Agent(instruction=visual_adjudicator_instruction, role="Visual Adjudicator")
    
    final_visual_reports = {}

    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_slice = {}
        
        ap_map = {int(re.search(r'(\d+)\.png$', p).group(1)): p for p in selected_ap}
        dp_map = {int(re.search(r'(\d+)\.png$', p).group(1)): p for p in selected_dp}
        pvp_map = {int(re.search(r'(\d+)\.png$', p).group(1)): p for p in selected_pvp}

        cprint(f"Submitting {len(selected_numbers)} fine-grained visual analysis tasks to be run in parallel...", 'magenta')
        for slice_num in selected_numbers:
            # ä¸ºå½“å‰åˆ‡ç‰‡å·ï¼Œæ˜ç¡®åœ°æ”¶é›†å…¶å¯¹åº”çš„3å¼ ç„¦ç‚¹å›¾ç‰‡
            focus_images_for_level = [ap_map.get(slice_num), dp_map.get(slice_num), pvp_map.get(slice_num)]
            
            if all(focus_images_for_level):
                # ã€ã€æ ¸å¿ƒä¿®æ­£ã€‘ã€‘
                # â€œç»ç†â€ç°åœ¨å°†æ­£ç¡®çš„å‚æ•°ï¼ˆ3å¼ ç„¦ç‚¹å›¾ç‰‡ï¼‰å§”æ‰˜ç»™â€œå·¥äººâ€å‡½æ•°
                future = executor.submit(
                    _analyze_single_slice_level_visual, 
                    agent_5, 
                    slice_num, 
                    focus_images_for_level # <-- ç°åœ¨æ­£ç¡®åœ°ä¼ é€’äº†3å¼ ç„¦ç‚¹å›¾ç‰‡
                )
                future_to_slice[future] = slice_num

        # ... (åç»­çš„tqdmå’Œç»“æœæ”¶é›†é€»è¾‘ä¸å˜) ...
        for future in tqdm(as_completed(future_to_slice), total=len(future_to_slice), desc="Adjudicating Slices"):
            slice_num = future_to_slice[future]
            result = future.result()
            final_visual_reports[slice_num] = result
            
    cprint("\n--- Fine-Grained Visual Adjudicator Output (by Slice) ---", 'green')
    print(json.dumps(final_visual_reports, indent=2, ensure_ascii=False))
    
    return final_visual_reports
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”







def run_phase_3(longitudinal_report, cross_sectional_report, visual_adjudicator_report):
    """
    æ‰§è¡Œç¬¬ä¸‰é˜¶æ®µï¼šè¿è¡Œé¦–å¸­æ•´åˆå®˜ï¼Œç»¼åˆæ‰€æœ‰åˆ†ææŠ¥å‘Šã€‚
    """
    cprint("ğŸ‘¨â€âš•ï¸ [Phase 3: Final Decision Making] ğŸ‘¨â€âš•ï¸", 'cyan', attrs=['bold'])
    
    # å‡†å¤‡ç»™é¦–å¸­æ•´åˆå®˜çš„è¾“å…¥ï¼Œç°åœ¨åŒ…å«ä¸‰ä»½æŠ¥å‘Š
    synthesis_input = f"""
    [Feature Evolution Report from Cross-Phase Analyst]:
    {longitudinal_report}
    [Diagnostic Snapshot Report from Pattern Recognition Analyst]:
    {cross_sectional_report}
    [Visual Adjudicator Report from Direct Image Analysis]:
    {visual_adjudicator_report}
    """
    cprint("\n[6. Chief Synthesizer] Synthesizing all three expert reports...", 'magenta')

    # Agent 5: é¦–å¸­æ•´åˆå®˜
    chief_synthesizer_prompt = f"""
You are the **Chief Radiologist** presiding over an AI diagnostic committee. Your task is to provide the final, global conclusion by synthesizing three expert reports.

**Your Inputs:**
1.  A **Feature Evolution Report** from the Cross-Phase Analyst (summarizing text-based findings over time).
2.  A **Diagnostic Snapshot Report** from the Pattern Recognition Analyst (summarizing text-based findings by phase).
3.  A **Visual Adjudicator Report** (based on direct analysis of all images, with confidence scores).

**Your Reasoning Process:**
Your primary job is to synthesize three expert perspectives to form a final, reasoned conclusion. Based on testing, the text-based analysis (reports 1 & 2) has been found to be more consistently reliable. Therefore, you must follow this **Conflict Resolution Protocol**:

1.  **Establish Primary Finding from Text:** First, for each of the 9 features, establish a "primary finding" by synthesizing the **Feature Evolution Report** and the **Diagnostic Snapshot Report** (reports 1 & 2). This text-based conclusion is your baseline.

2.  **Use Visual Report for Verification:** Next, use the **Visual Adjudicator Report** (report 3) to either **confirm** or **challenge** this primary finding.

3.  **Handle Agreement and Conflict:**
    * **If they AGREE:** The finding is confirmed with high confidence. Your justification should reflect this consensus.
    * **If they CONFLICT:** This indicates a significant discrepancy. You must handle it with caution:
        * **Default Stance:** Your default decision should be to **trust the primary finding from the text-based analysis (reports 1 & 2)**.
        * **Condition for Override:** You may only override the text-based finding and adopt the Visual Adjudicator's conclusion if, and only if, the Visual Adjudicator's report meets **BOTH** of these strict criteria:
            a) Its confidence score is the **maximum possible (e.g., 5/5)**.
            b) Its justification provides **exceptionally clear, unambiguous, and compelling evidence**, citing specific image numbers.
        * If the override condition is not met, you stick with the text-based finding.

4.  **Justify Your Final Decision:** In your final `justification` for each feature, you must be transparent about the process:
    * If the reports agreed, state the consensus. (e.g., *"Confirmed by both text-based analysis and direct visual review."*)
    * If there was a conflict that you resolved, explain your decision. (e.g., *"While the Visual Adjudicator reported a possible finding, the text-based analysis from all initial phase-analysts was consistently negative. Defaulting to the more reliable text-based consensus."* or *"Overriding the text-based analysis due to a definitive, max-confidence (5/5) visual findin

Your final output MUST be a single block of text that strictly follows the three-part structure outlined below. It is CRITICAL that you include the exact headings for each section, including the numbering.
**Required Output Format:**
1.  **Core Conclusion:** 
    A concise paragraph summarizing the overall clinical findings and conclusion.

2.  **Main Evidence:**
    A bulleted points detailing the key evidence from both the longitudinal, cross-sectional and visual reports that support your core conclusion.

3.  **Structured Summary:**
    This section MUST be a single, valid JSON object and nothing else. Do not add any introductory text, markdown tags like ```json, or any text after the JSON object.
    The JSON object must summarize the final answer for each of the 9 features. It must have keys from "pattern_1" to "pattern_9", corresponding to the features in this order:
    1. Enhancing Capsule
    2. Peritumoral Perfusion Alteration
    3. Peritumoral Hypodense Halo
    4. Corona Enhancement
    5. Custom TTPVI Feature
    6. Fade Enhancement Pattern
    7. Nodule-in-Nodule Architecture
    8. Peripheral Washout
    9. Delayed Central Enhancement

    For each pattern, the value must be an object with two keys:
    - "answer": The final binary conclusion (0 for first description, 1 for second description).
    - "justification": A brief, concise summary of the reasoning.

**Before generating the final output, double-check that the JSON syntax is perfect, especially for **Structured Summary:**, ensuring that a comma (`,`) separates every pattern object from the next.**

Example of the required structure for the JSON part ONLY:
```json
{{
    "pattern_1": {{
        "answer": 1,
        "justification": "Visible as a distinct, enhancing rim in the PVP/DP, which was not clearly defined in the AP."
    }},
    "pattern_2": {{
        "answer": 0,
        "justification": "No transient, wedge-shaped hyperenhancement was observed; any minor surrounding brightness in the AP persisted into the PVP."
    }},
    "pattern_7": {{
        "answer": 0,
        "justification": "The lesion's internal enhancement was reported as homogeneous across all three phases, lacking a distinct inner nodule."
    }}
}}
"""

    agent_6 = Agent(instruction=chief_synthesizer_prompt, role="Chief Synthesizer")
    final_hybrid_output = agent_6.chat(prompt_text=synthesis_input)
    # print(f"agent_6 output: \n{final_hybrid_output}")


    # ã€ã€æ–°ã€‘ã€‘å¢åŠ è§£æé€»è¾‘ï¼Œåˆ†ç¦»æ–‡æœ¬æŠ¥å‘Šå’ŒJSONå¯¹è±¡
    prose_report = ""

    try:
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¥åˆ†å‰²ï¼Œæ›´å¼ºå¤§ã€æ›´å®½å®¹
        pattern = re.compile(r'3\.\s*\**Structured\s+Summary\**:', re.IGNORECASE)
        parts = pattern.split(final_hybrid_output, 1)

        if len(parts) == 2:
            prose_report = parts[0].strip()
            json_text = parts[1].strip() # è¿™æ˜¯å¯èƒ½åŒ…å«æ‚è´¨çš„JSONæ–‡æœ¬
            
            # ã€ã€ã€æ ¸å¿ƒä¿®æ”¹ï¼šæ™ºèƒ½æå–ã€‘ã€‘ã€‘
            # ä»å¯èƒ½æ··æ‚çš„æ–‡æœ¬ä¸­ï¼Œç²¾ç¡®æ‰¾åˆ°ç¬¬ä¸€ä¸ª '{' å’Œæœ€åä¸€ä¸ª '}'
            start_index = json_text.find('{')
            end_index = json_text.rfind('}')

            if start_index != -1 and end_index != -1 and end_index > start_index:
                # ç²¾ç¡®æå–ä» '{' åˆ° '}' çš„æ‰€æœ‰å†…å®¹
                actual_json_text = json_text[start_index : end_index + 1]
                
                # ç°åœ¨å¯¹è¿™ä¸ªçº¯å‡€çš„å­—ç¬¦ä¸²è¿›è¡Œè§£æ
                structured_summary = json.loads(actual_json_text)
                cprint("âœ… Successfully extracted and parsed JSON.", 'green')
            else:
                # å¦‚æœè¿ '{' å’Œ '}' éƒ½æ‰¾ä¸åˆ°
                cprint("Error: Could not find a valid JSON object within the summary section.", "red")
                structured_summary = {"error": "JSON object start '{' or end '}' not found.", "raw_json_text": json_text}
        else:
            # å¦‚æœæ­£åˆ™è¡¨è¾¾å¼æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„åˆ†å‰²ç‚¹
            prose_report = final_hybrid_output
            structured_summary = {"error": "Structured Summary section heading not found in the output.", "raw_response": final_hybrid_output}

    except Exception as e:
        cprint(f"An unexpected error occurred during parsing: {e}", "red")
        prose_report = final_hybrid_output
        structured_summary = {"error": f"An unexpected error occurred. Details: {e}", "raw_response": final_hybrid_output}

    # --- æ‰“å°æœ€ç»ˆç»“æœ ---
    print("\n" + "="*20 + " åˆ†å‰²ç»“æœ " + "="*20)

    print("\n--- ç¬¬ä¸€éƒ¨åˆ†ï¼šæ–‡æœ¬æŠ¥å‘Š (Prose Report) ---")
    print(prose_report)

    print("\n--- ç¬¬äºŒéƒ¨åˆ†ï¼šç»“æ„åŒ–æ€»ç»“ (Structured Summary JSON) ---")
    # ä½¿ç”¨json.dumpsç¾åŒ–æ‰“å°è¾“å‡ºï¼Œæ–¹ä¾¿æŸ¥çœ‹
    print(json.dumps(structured_summary, indent=4, ensure_ascii=False))

    # è¿”å›ä¸¤ä¸ªéƒ¨åˆ†ï¼šæ–‡æœ¬æŠ¥å‘Šå’Œç»“æ„åŒ–å­—å…¸
    return prose_report, structured_summary
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”


















# --- 5. ä¸»æ‰§è¡Œé€»è¾‘ (Main Execution Logic) ---

def main():
    # (è¿™æ˜¯ä¸»å‡½æ•°ï¼Œè´Ÿè´£ç¼–æ’æ•´ä¸ªæµç¨‹)
    all_patient_results = {}
    all_selected_paths = {}

    try:
        patient_ids = [d for d in os.listdir(BASE_DATA_PATH) if os.path.isdir(os.path.join(BASE_DATA_PATH, d))]
        patient_ids.sort()
        if not patient_ids:
            cprint(f"Error: No patient folders found in '{BASE_DATA_PATH}'.", 'red')
            return
        cprint(f"Found {len(patient_ids)} patient folder(s). Starting processing...", 'cyan', attrs=['bold'])
    except FileNotFoundError:
        cprint(f"Error: The directory '{BASE_DATA_PATH}' was not found. Please check the path.", 'red')
        return

    for patient_id in tqdm(patient_ids, desc="Processed Patients"):
        cprint(f"\n{'='*20} Processing Patient: {patient_id} {'='*20}", 'yellow')
        patient_folder = os.path.join(BASE_DATA_PATH, patient_id)
        
        # ä¸ºæ¯ä¸ªæ—¶æœŸæ”¶é›†å›¾åƒè·¯å¾„
        image_paths_ap = sorted([os.path.join(patient_folder, 'AP', f) for f in os.listdir(os.path.join(patient_folder, 'AP')) if f.endswith('.png')])
        image_paths_dp = sorted([os.path.join(patient_folder, 'DP', f) for f in os.listdir(os.path.join(patient_folder, 'DP')) if f.endswith('.png')])
        image_paths_pvp = sorted([os.path.join(patient_folder, 'PVP', f) for f in os.listdir(os.path.join(patient_folder, 'PVP')) if f.endswith('.png')])
        
        if not all([image_paths_ap, image_paths_dp, image_paths_pvp]):
            cprint(f"Warning: Patient {patient_id} is missing images in one or more phase folders. Skipping.", 'red')
            continue

        # 1. ã€ã€æ–°ã€‘ã€‘è°ƒç”¨AIæ¥å¯»æ‰¾PVPæœŸç›¸çš„5å¼ æœ€ä½³ä»£è¡¨å›¾ç‰‡
        selected_numbers = select_best_five_slices(image_paths_pvp)

        if selected_numbers is None:
            cprint(f"Could not select representative slices for patient {patient_id}. Skipping.", 'red')
            all_selected_paths[patient_id] = {"error": "Slice selection failed."}
            continue

        # æ‰¾å‡ºè¿™5å¼ CTå›¾çš„è·¯å¾„åˆé›†
        selected_ap, selected_dp, selected_pvp = select_paths_by_numbers(
            selected_numbers,
            image_paths_ap,
            image_paths_dp,
            image_paths_pvp
        )
    
        # 3. ä¿å­˜æ¯ä¸ªæ—¶æœŸæŒ‘é€‰çš„5ä¸ªå›¾ç‰‡çš„path
        all_selected_paths[patient_id] = {
            "AP": selected_ap,
            "DP": selected_dp,
            "PVP": selected_pvp
        }
        cprint(f"Stored selected paths for patient {patient_id}.", "blue")





        # æ‰§è¡Œç¬¬ä¸€é˜¶æ®µï¼Œæ¯æ—¶æœŸ10å¼ å›¾
        phase1_report = run_phase_1(selected_ap, selected_dp, selected_pvp)
        # print(f"phase1 reports: {phase1_reports}")
        
        # 2. æ‰§è¡Œç¬¬äºŒé˜¶æ®µ
        # all_images = selected_paths_ap + selected_paths_dp + selected_paths_pvp
        phase2_report= run_phase_2(phase1_report, selected_numbers)

        # æ¯æ—¶æœŸ3å¼ å›¾
        visual_report = run_phase_visual(selected_ap, selected_dp, selected_pvp, selected_numbers)
        
        # 3. æ‰§è¡Œç¬¬ä¸‰é˜¶æ®µ
        # prose_report, structured_summary = run_phase_3(long_report, cross_report, visual_report)
        
        # æ”¶é›†ç»“æœ
        # all_patient_results[patient_id] = structured_summary







    # å°†æ‰€æœ‰ç—…äººæŒ‘é€‰çš„5ä¸ªå›¾ç‰‡çš„pathä¿å­˜åˆ°ä¸€ä¸ªJSONæ–‡ä»¶ä¸­
    output_filename = "selected_image_paths.json"
    try:
        with open(output_filename, 'w', encoding='utf-8') as f:
            json.dump(all_selected_paths, f, ensure_ascii=False, indent=4)
        cprint(f"\n\nâœ… Successfully saved all selected image paths to '{output_filename}'.", 'green', attrs=['bold'])
    except Exception as e:
        cprint(f"\n\nâŒ Failed to save selected paths. Error: {e}", 'red')


    # å°†æ‰€æœ‰ç—…äººçš„ç»“æœä¿å­˜åˆ°ä¸€ä¸ªJSONæ–‡ä»¶ä¸­
    output_filename = "selected_numbers.json"
    with open(output_filename, 'w', encoding='utf-8') as f:
        json.dump(all_patient_results, f, ensure_ascii=False, indent=4)
    
    cprint(f"\n\nğŸ‰ All processing complete. All reports have been saved to '{output_filename}'.", 'cyan', attrs=['bold'])


if __name__ == '__main__':
    main()
